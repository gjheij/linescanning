#!/usr/bin/env python
from linescanning import utils, dataset
import os
import pickle
import sys
import getopt
import numpy as np
import nibabel as nb
import pandas as pd
import glob
opj = os.path.join

def fetch_filepath(func, skip_run_id=False):

    # get bids components
    comps = utils.split_bids_components(func)

    # compile output name
    final_output=""
    for id in ['sub','ses','task','run','space','hemi']:
        if id in list(comps.keys()):
            if id == "sub":
                final_output+= f"{id}-{comps[id]}"
            else:
                if id == "run":
                    if not skip_run_id:
                        final_output+=f"_{id}-{comps[id]}"
                else:
                    final_output+=f"_{id}-{comps[id]}"

    base_dir = f"sub-{comps['sub']}"
    if "ses" in list(comps.keys()):
        base_dir = opj(base_dir, f"ses-{comps['ses']}")

    return final_output,base_dir

def unzscore(raw,data):

    if isinstance(raw, (np.ndarray,pd.DataFrame)):
        unz = raw*data["std"].T+data["avg"].T
        return unz.values
    else:
        r1 = raw.get_fdata()
        r2 = data["std"].get_fdata()[...,np.newaxis]
        r3 = data["avg"].get_fdata()[...,np.newaxis]

        # insert TR in header
        hdr = raw.header.copy()
        hdr["pixdim"][4] = float(data["tr"])

        # unzscore
        unz = r1*r2+r3
        return nb.Nifti1Image(unz, affine=raw.affine, header=hdr)

def read_data(func):

    if func.endswith(".nii.gz"):
        return nb.load(func)
    else:
        obj = dataset.Dataset(
            func, 
            use_bids=True, 
            filter_strategy='raw', 
            standardization='raw', 
            verbose=False)

        # get raw data
        raw = obj.fetch_fmri(dtype='raw')

        return raw

def calculate_std(raw):

    # get standard deviation and mean
    if isinstance(raw, (np.ndarray,pd.DataFrame)):
        stdev = raw.values.std(axis=0, keepdims=True)
        avg = raw.values.mean(axis=0, keepdims=True)

        tmp_data = {
            'std': stdev,
            'avg': avg
        }        
    else:
        data = raw.get_fdata()
        stdev = nb.Nifti1Image(data.std(axis=-1), affine=raw.affine, header=raw.header)
        avg = nb.Nifti1Image(data.mean(axis=-1), affine=raw.affine, header=raw.header)

        # save in pickle
        tmp_data = {
            'std': stdev,
            'avg': avg,
            'tr': raw.header["pixdim"][4]
        }

    return tmp_data

def bids_search(func, start_search=[], skip_run_id=False):
    
    # split into bids components to get run ID
    comps = utils.split_bids_components(func)
    
    output_base = f"sub-{comps['sub']}"
    if "ses" in list(comps.keys()):
        output_base = opj(output_base, f"ses-{comps['ses']}")

        if len(start_search) > 0:
            if not any("ses" in i for i in start_search):
                start_search += [f"ses-{comps['ses']}_"]

    for el in ["run","hemi","task","acq","space"]:

        if el in list(comps.keys()):

            add_el = True
            # define cases where element should not be appended
            if len(start_search) > 0:
                
                # don't add element if it's already in 'start_search'
                if any(el in i for i in start_search):
                    add_el = False

            # don't add run if skip_run_id == True
            if el == "run":
                if skip_run_id:
                    add_el = False
                    
            if add_el:
                start_search += [f"{el}-{comps[el]}_"]

    return start_search, output_base

def fetch_match_data(search_for, search_dir):

    # get standard deviation and mean
    match = utils.get_file_from_substring(search_for, search_dir)
    if isinstance(match, list):
        raise ValueError(f"Found {len(match)} matches with filters {search_for}: {match}")
    
    # print(f"found match: '{match}'")
    with open(match, 'rb') as in_file:
        data = pickle.load(in_file)
    
    return data

def write_pickle(data, fname):
    
    # print(f"Writing {pkl_file}")
    f = open(fname, "wb")
    pickle.dump(data, f)
    f.close()  

def main(argv):

    """
---------------------------------------------------------------------------------------------------
call_unzscore

Hook that allows you to undo the zscoring of pybest output; this should be called twice: First, 
with the '--pre' flag in order to calculate the standard deviation and average for each input file 
that is going to be found (based on the given filters) and processed by pybest. Then, with the '--
post' flag, but keeping the other inputs the same, we'll undo the zscoring by placing files with
exactly the same name as the pybest output in pybest/<subject>/<session>/unzscored. To utilize this 
as input for 'spinoza_fitprfs', use '--psc'. This will redirect the file searcher to the 'unzscored'
folder, and convert the inputs to percent signal change following M. Aqil's strategy. See 'call_prf'
docs for more information.

Args:
    -s|--sub <subject>  subject ID (e.g., "008")
    -n|--ses <session>  session ID   
    -f|--fprep <path>   path to fMRIPrep root folder (e.g., derivatives/fmriprep). Default is the environmental variable `DIR_DATA_DERIV/fmriprep`
    -o|--out <path>     path to pybest output. Default is the environmental variable `DIR_DATA_DERIV/pybest`
    -t|--task <task>    task ID
    -p|--space <space>  space ID. Default is `fsnative`
    --lh|--rh           Process a single hemisphere, default is to loop through both
    -q|--help           print help text
    --pre               use this *before* pybest; calculates the standard deviation and average and  stores it in <out>/<subject>/<ses>/tmp
    --post              use this *after* pybest; undo the z-scoring using the output from `--tmp`

Example:
    call_unzscore -s 999 -n 1 --pre
    call_unzscore -s 999 -n 1 --post
    call_unzscore -s 999 -n 1 -f $DIR_DATA_DERIV/fmriprep -f $DIR_DATA_DERIV/pybest --pre

---------------------------------------------------------------------------------------------------
    """

    # set defaults
    fprep_dir   = opj(os.environ.get("DIR_DATA_DERIV"), 'fmriprep')
    out_dir     = opj(os.environ.get("DIR_DATA_DERIV"), 'pybest')
    subject     = None
    session     = None
    task        = None
    space       = "fsnative"
    hemi_list   = ['L', 'R']
    pre         = True
    skip_run_id = False

    try:
        opts = getopt.getopt(argv,"qf:o:s:n:t:h:p:",["fprep=", "lh", "rh", "out=", "sub=", "ses=", "task=", "space=", "hemi=", "post", "pre", "help"])[0]
    except getopt.GetoptError:
        print(main.__doc__)
        sys.exit(2)

    for opt, arg in opts:
        if opt in ('-q', 'help'):
            print(main.__doc__)
            sys.exit()
        elif opt in ("-f", "--fprep"):
            fprep_dir = arg
        elif opt in ("-o", "--out"):
            out_dir = arg
        elif opt in ("-s", "--sub"):
            subject = arg
        elif opt in ("-n", "--ses"):
            session = arg
        elif opt in ("-t", "--task"):
            task = arg
        elif opt in ("-p", "--space"):
            space = arg
        elif opt in ("--lh"):
            hemi_list = ["L"]
        elif opt in ("--rh"):
            hemi_list = ["R"]
        elif opt in ('--pre'):
            pre = True
        elif opt in ('--post'):
            pre = False

    if len(argv) < 2:
        print("NOT ENOUGH ARGUMENTS SPECIFIED")
        print(main.__doc__)
        sys.exit(1)

    # initiate search parameters
    base_dir = f'sub-{subject}'
    search_for = [f'sub-{subject}']

    if session != None:
        if session != "all":
            search_for += [f'ses-{session}_']

    if task != None:
        search_for += [f'task-{task}']

    # check if inputs are niftis
    is_nifti = False
    extension = "npy"
    exclude = None
    if isinstance(space, str):
        if not "fs" in space:
            is_nifti = True
            extension = "nii.gz"
            search_hemi = []

            search_for += ["desc-preproc_bold.nii.gz"]
            if space != "func":
                search_for += [f'space-{space}']
            else:
                exclude = "space-"
        else:
            search_for += [f'space-{space}']
    
    # pre-pybest workflow; saves std and mean
    if pre:

        if is_nifti:

            # final func_dir
            ffunc_dir = utils.FindFiles(opj(fprep_dir, f'sub-{subject}'), extension="nii.gz").files

            # load data
            funcs = utils.get_file_from_substring(search_for, ffunc_dir, exclude="json")
            if isinstance(funcs, str):
                skip_run_id = True
                funcs = [funcs]

            # get session IDs
            ses_ids = utils.get_ids(funcs, bids="ses")
            if len(ses_ids) > 0:
                for ses in ses_ids:
                    
                    ses_funcs = utils.get_file_from_substring([f"ses-{ses}_"], funcs, exclude=exclude)
                    if isinstance(ses_funcs, str):
                        ses_funcs = [ses_funcs]
                    
                    # get run ids
                    skip_run_id = False
                    run_ids = utils.get_ids(ses_funcs, bids="run")
                    if len(run_ids) == 1:
                        skip_run_id = True

                    for func in ses_funcs:
                        
                        utils.verbose(f" {func}", True)
                        # construct output basename and base output dir
                        final_output, base_dir = fetch_filepath(func, skip_run_id=skip_run_id)

                        # make output directory
                        output_dir = opj(out_dir, base_dir, 'tmp')
                        if not os.path.exists(output_dir):
                            os.makedirs(output_dir, exist_ok=True)
                        
                        # read in file
                        raw = read_data(func)
                        write_data = calculate_std(raw)
                        
                        # write file
                        pkl_file = opj(output_dir, final_output+'_desc-avgstd.pkl')
                        write_pickle(write_data, pkl_file)
            else:
                # get run ids
                skip_run_id = False
                run_ids = utils.get_ids(funcs, bids="run")
                if len(run_ids) == 1:
                    skip_run_id = True

                for func in funcs:
                    
                    print(f" {func}")
                    # construct output basename and base output dir
                    final_output, base_dir = fetch_filepath(func, skip_run_id=skip_run_id)

                    # make output directory
                    output_dir = opj(out_dir, base_dir, 'tmp')
                    if not os.path.exists(output_dir):
                        os.makedirs(output_dir, exist_ok=True)

                    # read in file
                    raw = read_data(func)
                    write_data = calculate_std(raw)   
                    
                    # write file
                    pkl_file = opj(output_dir, final_output+'_desc-avgstd.pkl')
                    write_pickle(write_data, pkl_file)  
        else:

            for hemi in hemi_list:

                if hemi != None:
                    search_hemi = search_for + [f'hemi-{hemi}']    

                if pre:

                    # final func_dir
                    ffunc_dir = utils.FindFiles(opj(fprep_dir, f'sub-{subject}'), extension="gii").files

                    # load data
                    funcs = utils.get_file_from_substring(search_hemi, ffunc_dir, exclude="json")
                    if isinstance(funcs, str):
                        skip_run_id = True
                        funcs = [funcs]

                    # get session IDs
                    ses_ids = utils.get_ids(funcs, bids="ses")
                    if len(ses_ids) > 0:
                        for ses in ses_ids:
                            
                            ses_funcs = utils.get_file_from_substring([f"ses-{ses}_"], funcs)
                            if isinstance(ses_funcs, str):
                                ses_funcs = [ses_funcs]
                            
                            # get run ids
                            skip_run_id = False
                            run_ids = utils.get_ids(ses_funcs, bids="run")
                            if len(run_ids) == 1:
                                skip_run_id = True

                            for func in ses_funcs:
                                
                                utils.verbose(f" {func}", True)
                                # construct output basename and base output dir
                                final_output, base_dir = fetch_filepath(func, skip_run_id=skip_run_id)

                                # make output directory
                                output_dir = opj(out_dir, base_dir, 'tmp')
                                if not os.path.exists(output_dir):
                                    os.makedirs(output_dir, exist_ok=True)
                                
                                # read in file
                                raw = read_data(func)
                                write_data = calculate_std(raw)

                                # write file
                                pkl_file = opj(output_dir, final_output+'_desc-avgstd.pkl')
                                write_pickle(write_data, pkl_file)
                    else:
                        # get run ids
                        skip_run_id = False
                        run_ids = utils.get_ids(funcs, bids="run")
                        if len(run_ids) == 1:
                            skip_run_id = True

                        for func in funcs:
                            
                            # print
                            utils.verbose(f" {func}", True)

                            # construct output basename and base output dir
                            final_output, base_dir = fetch_filepath(func, skip_run_id=skip_run_id)

                            # make output directory
                            output_dir = opj(out_dir, base_dir, 'tmp')
                            if not os.path.exists(output_dir):
                                os.makedirs(output_dir, exist_ok=True)

                            # read in file
                            raw = read_data(func)
                            write_data = calculate_std(raw)

                            # write file
                            pkl_file = opj(output_dir, final_output+'_desc-avgstd.pkl')
                            write_pickle(write_data, pkl_file)                                       
    else:
        
        # find all files
        all_files = utils.FindFiles(opj(out_dir, base_dir), extension=extension).files

        # load data; check if we can load with 'run' flag, otherwise we only have a single run
        full_search = search_for + ['denoised_bold','denoising']

        # filter out remnants from nifti-specification
        if is_nifti:
            full_search = utils.get_file_from_substring([], full_search, exclude="desc-preproc_bold.nii.gz")

        funcs = utils.get_file_from_substring(full_search, all_files, exclude="raw")

        if isinstance(funcs, str):
            funcs = [funcs]

        if len(funcs) == 0:
            raise ValueError(f"No files with {full_search} in '{opj(out_dir, base_dir)}/*'")

        # get session IDs
        ses_ids = utils.get_ids(funcs, bids="ses")
        if len(ses_ids) > 0:
            for ses in ses_ids:

                ses_funcs = utils.get_file_from_substring([f"ses-{ses}/", f"ses-{ses}_"], funcs, exclude=exclude)
                if isinstance(ses_funcs, str):
                    ses_funcs = [ses_funcs]
                
                # get run ids
                skip_run_id = False
                run_ids = utils.get_ids(ses_funcs, bids="run")
                if len(run_ids)<2:
                    skip_run_id = True  

                # filter out run-ID if present
                if not skip_run_id:
                    ses_funcs = utils.get_file_from_substring(["run-"], ses_funcs)

                # make string again
                if isinstance(ses_funcs, str):
                    ses_funcs = [ses_funcs]
                
                for func in ses_funcs:
                    
                    # split into bids components to get run ID
                    all_search, output_base = bids_search(func, start_search=[], skip_run_id=skip_run_id)

                    # set tmp directory containing pkl-files
                    avg_dir = opj(out_dir, output_base, 'tmp')
                    output_dir = opj(out_dir, output_base, 'unzscored')

                    if not os.path.exists(output_dir):
                        os.makedirs(output_dir, exist_ok=True)

                    # read in file; returns nibabel.Nifti1Image if extension == "nii.gz"
                    raw = read_data(func)

                    # find matching pkl-file
                    data = fetch_match_data(all_search, avg_dir)
                    
                    # undo zscore
                    unzscored = unzscore(raw,data)

                    # sort nifti dimensions
                    fname = opj(output_dir, os.path.basename(func))
                    print(f" Writing {fname}")
                    if extension == "nii.gz":
                        unzscored.to_filename(fname)
                    else:
                        np.save(fname, unzscored.T)
        else:   

            # get run ids
            skip_run_id = False
            run_ids = utils.get_ids(funcs, bids="run")
            if len(run_ids) == 1:
                skip_run_id = True

            if not skip_run_id:
                funcs = utils.get_file_from_substring(["run-"], funcs)
            
            for func in funcs:

                # split into bids components to get run ID
                all_search, output_base = bids_search(func, start_search=[], skip_run_id=skip_run_id)

                # set tmp directory containing pkl-files
                avg_dir = opj(out_dir, output_base, 'tmp')
                output_dir = opj(out_dir, output_base, 'unzscored')

                if not os.path.exists(output_dir):
                    os.makedirs(output_dir, exist_ok=True)

                # read in file
                raw = read_data(func)

                # find matching pkl-file
                data = fetch_match_data(all_search, avg_dir)

                # undo zscore
                unzscored = unzscore(raw,data)

                # sort nifti dimensions
                fname = opj(output_dir, os.path.basename(func))
                print(f" Writing {fname}")
                if extension == "nii.gz":
                    unzscored.to_filename(fname)
                else:
                    np.save(fname, unzscored.T)
                        
if __name__ == "__main__":
    main(sys.argv[1:])
