#!/usr/bin/env python
#$ -j Y
#$ -cwd
#$ -V

import mkl
mkl.set_num_threads=1

from linescanning import (
    prf, 
    utils)
import os
import sys, getopt
import pandas as pd
import ast
opj = os.path.join

def main(argv):

    """
---------------------------------------------------------------------------------------------------
call_sizeresponse

Create size-response curves given a set of pRF estimates from the DN-model. Aside from size-response
functions, we can also create hole-response functions - which simulate the response of a pRF to sti-
muli of growing holes starting from a full field stimulus. This is a proxy for suppression response
of a given pRF. You can choose to center the pRFs in the middle of the screen (= faster), or create
a stimulus set specific for each pRF (= slower, but more accurate representation).

Parameters
----------
    -i|--in_file    file containing pRF estimates; if formatted according to BIDS, we can derive an 
                    output name from its elements
    -o|--out_file   output dataframe indexed on subject, stimulus type, stimulus size, by nr of ver-
                    tices. If nothing is specified, we'll try to read the file components from `in_
                    file`, and append {"_desc-srfs_unique.csv"|"_desc-srfs_centered.csv"}
    --unique        create unique stimulus sets for each pRF so that the simulation is more accurate. 
                    Default is to center the pRF in the visual field
    --act_only      Only create size-response functions (activation component)
    --suppr_only    Only create hole-response functions (suppression component)
    --screen_dist   Distance viewer to screen (default = 196cm)
    --screen_cm     Screen sizes for x,y. Default is [70,39.8], representing the actual screen size.
                    If you want a square screen, specify 1 value
    --screen_pix    Nr of pixels on the screen for x,y. Default is [1920,1080]. If you want a
                    square screen, specify 1 value
    --factor        stimulus factor; the lower the number, the larger the stimulus range. Default 
                    = 1, resulting in stimulus sizes of 20dva
    --verbose       turn on verbosity; prints some stuff to the terminal along the way
    --parallel      run jobs in parallel

Returns
----------
    a *csv-file containing a  dataframe indexed on subject, stimulus type, stimulus size by nr of 
    vertices

Example
----------
    call_sizeresponse -i sub-01_ses-1_task-2R_model-norm_stage-iter_desc-prf_params.pkl
    call_sizeresponse -i prf_estimates.pkl -o srfs.csv --unique
    in_file=/data1/projects/MicroFunc/Jurjen/projects/VE-SRF/derivatives/prf/sub-005/ses-1/sub-005_ses-1_task-2R_model-norm_stage-iter_desc-prf_params.pkl; qsub -N $(basename ${in_file} prf_params.pkl)srfs_centered -q long.q -pe smp 20 -wd $(dirname ${in_file}) $DIR_SCRIPTS/bin/call_sizeresponse -i ${in_file} --verbose --parallel

---------------------------------------------------------------------------------------------------
    """

    in_file = None
    out_file = None
    center_prf = True
    verbose = False
    srf_act = True
    srf_suppr = True
    screen_distance_cm = 196
    screen_size_cm = [70,39.8]
    screen_size_px = [1920,1080]
    stim_factor = 1
    parallel = False

    try:
        opts = getopt.getopt(argv,"hi:o:",["help", "in_file=", "out_file=", "unique", "act_only", "suppr_only", "screen_dist=", "screen_cm=", "screen_pix=", "factor=", "verbose", "parallel"])[0]
    except getopt.GetoptError:
        print("ERROR IN ARGUMENT HANDLING!")
        print(main.__doc__)
        sys.exit(2)

    for opt, arg in opts:
        if opt in ('-h', "--help"):
            print(main.__doc__)
            sys.exit()
        elif opt in ('-i', "--in_file"):
            in_file = arg
        elif opt in ('-o', "--out_file"):
            out_file = arg
        elif opt in ("--unique"):
            center_prf = False
        elif opt in ("--act_only"):
            srf_act = True
            srf_suppr = False
        elif opt in ("--suppr_only"):
            srf_act = False
            srf_suppr = True
        elif opt in ("--screen_dist"):
            screen_distance_cm = arg
        elif opt in ("--screen_cm"):
            screen_size_cm = ast.literal_eval(arg)
        elif opt in ("--screen_pix"):
            screen_size_px = ast.literal_eval(arg)
        elif opt in ("--factor"):
            stim_factor = arg
        elif opt in ("--verbose"):
            verbose = True
        elif opt in ("--parallel"):
            parallel = True      

    if len(argv) < 1:
        print("\nNEED AT LEAST A FILE WITH PRF ESTIMATES")
        print(main.__doc__)
        sys.exit()

    if not os.path.exists(in_file):
        raise FileNotFoundError(f"Could not find file '{in_file}'..")
    else:
        in_file = os.path.abspath(in_file)
        out_dir = os.path.dirname(in_file)

    # read the input file into a dataframe
    df_for_srfs = prf.Parameters(in_file, model="norm").to_df()

    # size response functions
    SR_ = prf.SizeResponse(
        params=df_for_srfs, 
        model="norm",
        screen_distance_cm=screen_distance_cm,
        screen_size_cm=screen_size_cm,
        screen_size_px=screen_size_px,
        verbose=verbose
    )
    
    # derive file components
    try:
        file_components = utils.split_bids_components(os.path.basename(in_file))
    except:
        file_components = []

    out_comps = []
    if len(file_components) > 0:
        for comp in ['sub', 'ses', 'task', 'acq', 'rec', 'run', 'space', 'hemi', 'model', 'stage']:
            if comp in file_components.keys():
                out_comps.append(f"{comp}-{file_components[comp]}")
    
    if len(out_comps) == 0:
        subject = "sub-01"
        out_comps = [subject]
    else:
        subject = out_comps[0]

    # append stuff based on centering of pRF or not
    if not center_prf:
        out_comps.append("desc-srfs_unique.pkl")
    else:
        out_comps.append("desc-srfs_centered.pkl")

    # check if we got a specified output file
    if not isinstance(out_file, str):
        out_file = opj(out_dir, "_".join(out_comps))

    utils.verbose(f"Creating {out_file}", verbose)
    
    #SRFs for activation & normalization parameters
    srfs = []
    if srf_act:

        # create singular stimulus-set if center_prf=True
        if center_prf:
            stims,sizes = SR_.make_stimuli(
                factor=stim_factor,
                dt="fill")
        else:
            stims = "fill"

        sr_fill = SR_.batch_sr_function(
            SR_.params_df,
            stims=stims,
            sizes=sizes,
            parallel=parallel,
            center_prf=center_prf)
        
        sr_fill["type"] = "act"
        srfs.append(sr_fill)

    if srf_suppr:

        # create singular stimulus-set if center_prf=True
        if center_prf:
            stims,sizes = SR_.make_stimuli(
                factor=stim_factor,
                dt="hole")
        else:
            stims = "hole"

        sr_hole = SR_.batch_sr_function(
            SR_.params_df,
            stims=stims,
            sizes=sizes,
            parallel=parallel,
            center_prf=center_prf)
        
        sr_hole["type"] = "norm"
        srfs.append(sr_hole)
    
    # add indices
    df_sr = pd.concat(srfs)
    df_sr["subject"] = subject
    df_sr = df_sr.set_index(["subject","type","sizes","stim_nr"]) 

    # save
    df_sr.to_pickle(out_file)
    utils.verbose("Done", verbose)

if __name__ == "__main__":
    main(sys.argv[1:])
