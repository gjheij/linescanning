#!/usr/bin/env python
#$ -j Y
#$ -cwd
#$ -V

import ast
import getopt
from linescanning import (
    prf,
    utils,
    dataset
)
import numpy as np
import nibabel as nb
import os
from scipy import io
import sys
import warnings
import json
import pickle
warnings.filterwarnings('ignore')
opj = os.path.join

def main(argv):

    """
---------------------------------------------------------------------------------------------------
call_prf

Wrapper for population receptive field fitting with pRFpy. If not present yet, it will create a
design matrix based on a specified path to screenshots as outputted by the pRF-experiment script.
If you're not running that particular experiment, you'll need to create a design matrix yourself.
Assumes the input is BIDS compliant, as it will extract certain features from the filenames.
Currently compatible with output from pybest (ending with "*desc-denoised_bold.npy") and from fMRI-
Prep (ending with "*bold.func.gii"). It will throw an error if neither of these conditions are met.
If you have a different case (e.g., nifti's), please open an issue so we can deal with that. We'll 
select files from the input directory based on 'space-' (check spinoza_setup)/'run-'/'task-IDs. They
are then paired into left+right hemisphere. Finally, the median over all runs is calculated and in-
serted in the model-fitting object.

Usage:
  call_prf [arguments] [options]

Arguments:
    -s|--sub    <sub number>        number of subject's FreeSurfer directory from which you can 
                                    omit "sub-" (e.g.,for "sub-001", enter "001").
    -n|--ses    <session number>    session number (e.g., "1")
    -t|--task   <task name>         name of the experiment performed (e.g., "2R")
    -o|--out    <prf dir>           output directory containing pRF-stuff (/derivatives/prf)
    -i|--in     <input dir>         input directory (e.g., output of pybest/fMRIPrep)
    -p|--png    <path to pngs>      path to png's if you ran M. Aqil's experiment
    -m|--model  <model type>        one of ['gauss','dog','css','norm'], default = 'gauss'
    -x|--params <gaussian params>   path to numpy array containing old parameters of Gaussian model
                                    to use for the Normalization model
    -u|--space  <fit space>         default is set as PYBEST_SPACE in spinoza_setup
    -c|--constr <constraints>       string or list representing the type of constraints to use for
                                    each stage (Gaussian and beyond). By default, we'll use trust-
                                    constr minimization ('tc'), but you can speed up the normaliza-
                                    tion fitting by using L-BGFS ('bgfs'). To specify a list, use 
                                    the format '-c [tc,bgfs]'. Use --tc or --bgfs to sync the mini-
                                    mizers across stages
    --cut_vols <volumes>            Number of volumes to remove at the beginning of the timeseries. 
                                    Default is 0, but sometimes it's good to get rid of the initial
                                    transient

Options:                                  
    --hrf           Fit the HRF during pRF-fitting. If `True`, the fitting will consist of two 
                    stages: first, a regular fitting without HRF estimation. Then, the fitting 
                    object of that fit is inserted as `previous_gaussian_fitter` into a new fitter 
                    object with HRF estimation turned on. Default = False.
    --clip          clip the edges of design matrix in the space of 'n_pix' (by default = 100). 
                    You will need to calculate how many pixels are to be set to zero given the vi-
                    sual field of the subject in the scanner (with a screensize of [1920,1080]px
                    and height of 39.3cm). Format needs to be '--clip "a,b,c,d"' or --clip [a,b,c,d]
                    to ensure it's read in like a list. Negative values will be set to zero within
                    `linescanning.prf.get_prfdesign`
    -g|--grid       only run a grid-fit with the specified model
    -v|--verbose    print some stuff to a log-file
    --file_ending   Overwrite default search-targets from pybest/fMRIPrep output. E.g., for fMRI-
                    Prep, we look for 'bold.func.gii' and 'desc-denoised_bold.npy' for Pybest. With
                    <file_ending> you can specify to use the volumetric data from fMRIPrep (e.g., 
                    preproc_bold.nii.gz [also requires different 'space-' flag!]). If volumetric
                    data is supplied, we'll convert it to 2D with `linescanning.dataset.Dataset`.
                    If you want to provide cifti's or nifti's, we assume everything's been prepro-
                    cessed appropriately. There's no filtering, percent-signal changing or other
                    stuff.
    --zscore        Do NOT convert the data to percent signal change. If you do want percent signal
                    change, the input directory needs to be unzscored data.
                    PSC will be calculated following M. Aqil's strategy:
                        psc = signals*100/(mean(signals)) - median(signals_without_stimulus)
                    This will ensure the baseline of periods without stimulus are set to zero.
    --overwrite     If specified, we'll overwrite existing Gaussian parameters. If not, we'll look
                    for a file with ['model-gauss', 'stage-iter', 'params.npy'] in *outputdir* and,
                    if it exists, inject it in the normalization model (if `model=norm`)  
    --tc            use trust-constr minimization for both the Gaussian as well as the extended mo-
                    del. 
                    Use the -x flag if you want different minimizers for both stages
    --bgfs          use L-BGFS minimization for both the Gaussian as well as the extended model. Use 
                    the -x flag if you want different minimizers for both stages                      
    --no_fit        Stop the process before fitting, right after saving out averaged data. This was 
                    useful for me to switch to percent-signal change without requiring a re-fit.
    --raw           use unzscore'd data from pybest; do not percent-signal change.

Example:
  call_prf -s 001 -n 1 -t 2R -o /path/derivatives/prf -i /path/to/pybest/sub-001 -p /path/png
  call_prf --sub 001 --ses 1 --task 2R --out /path/derivatives/prf --in /path/to/pybest/sub-001

---------------------------------------------------------------------------------------------------
"""

    sub         = None
    ses         = None
    task        = None
    outputdir   = None
    inputdir    = None
    png_dir     = None
    model       = "gauss"
    stage       = "iter"
    grid_only   = False
    space       = None
    giftis      = False
    fit_hrf     = False
    verbose     = False
    n_pix       = 100
    clip_dm     = [0,0,0,0]
    file_ending = None
    psc         = True
    overwrite   = False
    constraints = "tc"
    do_fit      = True
    cut_vols    = 0

    try:
        opts = getopt.getopt(argv,"ghs:n:t:o:i:p:m:x:u:c:v:",["help", "sub=", "model=", "ses=", "task=", "out=", "in=", "png=", "params=", "grid", "space=", "hrf", "n_pix=", "clip=", "verbose", "file_ending=", "zscore", "overwrite", "constr=", "tc", "bgfs", "no_fit", "raw", "cut_vols="])[0]
    except getopt.GetoptError:
        print("ERROR while reading arguments; did you specify an illegal argument?")
        print(main.__doc__)
        sys.exit(2)
    
    for opt, arg in opts:
        if opt in ('-h', '--help'):
            print(main.__doc__)
            sys.exit()
        elif opt in ("-s", "--sub"):
            sub = arg
        elif opt in ("-n", "--ses"):
            ses = int(arg)
        elif opt in ("-t", "--task"):
            task = arg
        elif opt in ("-o", "--out"):
            outputdir = arg
        elif opt in ("-i", "--in"):
            inputdir = arg
        elif opt in ("-p", "--png"):
            png_dir = arg
        elif opt in ("-m", "--model"):
            model = arg
        elif opt in ("-u", "--space"):
            space = arg
        elif opt in ("-g", "--grid"):
            grid_only = True
        elif opt in ("--hrf"):
            fit_hrf = True
        elif opt in ("--n_pix"):
            n_pix = int(arg)
        elif opt in ("-v", "--verbose"):
            verbose = True
        elif opt in ("--clip"):
            clip_dm = list(ast.literal_eval(arg))
        elif opt in ("--file_ending"):
            file_ending = arg
        elif opt in ("--zscore"):
            psc = False
        elif opt in ("--raw"):
            psc = False            
        elif opt in ("--overwrite"):
            overwrite = True
        elif opt in ("--tc"):
            constraints = "tc"
        elif opt in ("--bgfs"):
            constraints = "bgfs"
        elif opt in ("--no_fit"):
            do_fit = False
        elif opt in ("--constr"):
            constraints = utils.string2list(arg)
        elif opt in ("--cut_vols"):
            cut_vols = int(arg)
            
    if len(argv) < 2:
        print(main.__doc__)
        sys.exit()

    # check clip input:
    if isinstance(clip_dm, str):
        if clip_dm.endswith("json"):
            ff = open(clip_dm)
            clip_dm = json.load(ff)
            ff.close()
        elif clip_dm.endswith("txt"):
            clip_dm = np.loadtxt(clip_dm)
            if len(clip_dm) != 4:
                raise ValueError(f"Length of given list for clipping must be 4, not '{len(clip_dm)}': {clip_dm}")
            else:
                # make integer
                clip_dm = clip_dm.astype(int)
        elif clip_dm.endswith("yml"):
            with open(clip_dm, 'rb') as input:
                settings = pickle.load(input)

            if "screen_delim" in list(settings.keys()):
                screen_set = settings["screen_delim"]
                clip_dm = [
                    screen_set["top"],
                    screen_set["bottom"],
                    screen_set["left"],
                    screen_set["right"]
                ]

    out = f"sub-{sub}"
    if ses != None:
        out += f"_ses-{ses}"
    
    if task != None:
        out += f"_task-{task}"

    # Create design matrix if it doesn't exists
    design_file = opj(outputdir, f'design_task-{task}.mat')
    if os.path.isfile(design_file):
        if verbose:
            print(f"Design matrix: {design_file}", flush=True)
        design_matrix = io.loadmat(design_file)
    else:
        print("Creating new design matrix", flush=True)
        if os.path.isdir(png_dir):
            try:
                dm = prf.get_prfdesign(png_dir, n_pix=n_pix, dm_edges_clipping=clip_dm)
            except:
                raise TypeError(f"Failed to create {design_file}")

            io.savemat(design_file, {"stim": dm})
            design_matrix = io.loadmat(design_file)
        else:
            print("\n---------------------------------------------------------------------------------------------------")
            print(f"ERROR in {os.path.basename(__file__)}: invalid directory '{png_dir}'")
            sys.exit(1)

    # fetch available runs
    if file_ending == None:
        if "pybest" in inputdir:
            file_ending = "desc-denoised_bold.npy"
        elif "fmriprep" in inputdir:
            file_ending = "bold.func.gii"
            giftis = True
        else:
            raise ValueError(f"Unknown input directory '{inputdir}'. Expecting output from pybest ('*desc-denoised_bold.npy') or fMRIPrep ('*bold.func.gii')")

    # search for space-/task-/ and file ending; add run as well to avoid the concatenated version being included
    search_for = ["run-", f"task-{task}", file_ending]
    if space != None:
        search_for += [f"space-{space}"]

    # no space means native BOLD
    files = utils.get_file_from_substring(search_for, inputdir)
    
    if verbose:
        print("Loading in data", flush=True)
        for ff in files:
            print(f" {ff}", flush=True)
    
    if not files[0].endswith(".nii.gz") and not files[0].endswith(".nii"):
        # chunk into L/R pairs
        hemi_pairs = [[i, j] for i, j in zip(files[:-1], files[1:])]

        # load them in
        prf_tc_data = []
        for pair in hemi_pairs:
            
            if giftis:
                hemi_data = [dataset.ParseGiftiFile(pair[ix]).data for ix in range(len(pair))]
            else:
                hemi_data = [np.load(pair[ix]) for ix in range(len(pair))]
            
            prf_tc_data.append(np.hstack(hemi_data))

        # take median of data
        m_prf_tc_data = np.median(np.array(prf_tc_data), 0)
    else:
        obj = dataset.Dataset(
            files,
            verbose=verbose, 
            standardization='raw', 
            use_bids=True, 
            filter_strategy="raw")

        # get pandas dataframe with all runs
        prf_tc_data = obj.fetch_fmri()

        # get run IDs
        run_ids = obj.get_runs(prf_tc_data)

        # loop through run IDs and get median into <time,voxels> array
        m_prf_tc_data = np.median([utils.select_from_df(prf_tc_data, expression=f"run = {ii}").values for ii in run_ids], axis=0)

    if space == "fsnative":
        # vertices per hemi
        n_verts = [ii.shape[-1] for ii in hemi_data]

        # check if this matches with FreeSurfer surfaces
        n_verts_fs = []
        for i in ['lh', 'rh']:
            surf = opj(os.environ.get('SUBJECTS_DIR'), f"sub-{sub}", 'surf', f'{i}.white')
            verts = nb.freesurfer.io.read_geometry(surf)[0].shape[0]
            n_verts_fs.append(verts)

        if n_verts_fs != n_verts:
            raise ValueError(f"Mismatch between number of vertices in pRF-analysis ({n_verts}) and FreeSurfer ({n_verts_fs})..?\nYou're probably using an older surface reconstruction. Check if you've re-ran fMRIprep again with new FreeSurfer-segment")

    # cut volumes at the beginning of the timeseries. Also subtract number of volumes from baseline
    if verbose:
        print(f"Cutting {cut_vols} from beginning of timeseries", flush=True)
        
    m_prf_tc_data = m_prf_tc_data[cut_vols:,:]

    # default baseline is 15 volumes
    baseline = 15-cut_vols 

    # convert to psc according to baseline (as per Serge Dumoulin).
    if psc:
        if verbose:
            print("Converting to percent signal change and fix baseline", flush=True)

        m_prf_tc_data = utils.percent_change(m_prf_tc_data, 0, baseline=baseline)

    # save files
    if verbose:
        print("Saving averaged data", flush=True)
        
    np.save(opj(outputdir, f'{out}_hemi-LR_desc-avg_bold.npy'), m_prf_tc_data)
    np.save(opj(outputdir, f'{out}_hemi-L_desc-avg_bold.npy'), m_prf_tc_data[:,:n_verts[0]])
    np.save(opj(outputdir, f'{out}_hemi-R_desc-avg_bold.npy'), m_prf_tc_data[:,n_verts[0]:])
    
    if do_fit:

        # assume TR (read from gifti if possible)
        if giftis:
            tr = dataset.ParseGiftiFile(pair[0]).TR_sec
            if verbose:
                print(f"Setting TR to {tr}", flush=True)
        else:
            if verbose:
                print("Could not find func-file, setting TR to 1.5; CHECK THIS!", flush=True)
            tr = 1.5        

        # plop everything if pRFmodelFitting object
        if grid_only:
            stage = "grid"

        if not overwrite:
            # check if we have existing Gaussian pRFs that we should insert in DN-model
            old_params = utils.get_file_from_substring(['model-gauss', 'stage-iter', 'params.pkl'], outputdir, return_msg=None)
            if verbose:
                if old_params != None:
                    print(f"Injecting '{old_params}' into {model}-model", flush=True)
        else:
            old_params = None

        # stage 1 - no HRF
        stage1 = prf.pRFmodelFitting(
            m_prf_tc_data.T, 
            design_matrix=design_matrix[list(design_matrix.keys())[-1]], 
            TR=tr, 
            model=model, 
            stage=stage, 
            verbose=verbose, 
            output_dir=outputdir,
            output_base=out,
            write_files=True,
            fit_hrf=False,
            fix_bold_baseline=psc,
            old_params=old_params,
            constraints=constraints)

        stage1.fit()

        # stage2 - fit HRF after initial iterative fit
        if fit_hrf:

            previous_fitter = f"{model}_fitter"
            if not hasattr(stage1, previous_fitter):
                raise ValueError(f"fitter does not have attribute {previous_fitter}")

            # add tag to output to differentiate between HRF=false and HRF=true
            out += "_hrf-true"

            # initiate fitter object with previous fitter
            stage2 = prf.pRFmodelFitting(
                m_prf_tc_data.T, 
                design_matrix=stage1.design, 
                TR=stage1.TR, 
                model=model, 
                stage=stage, 
                verbose=stage1.verbose,
                fit_hrf=True,
                output_dir=stage1.output_dir,
                output_base=out,
                write_files=True,                                
                previous_gaussian_fitter=stage1.previous_fitter,
                fix_bold_baseline=psc,
                constraints=constraints)

            stage2.fit()    

if __name__ == "__main__":
    main(sys.argv[1:])
