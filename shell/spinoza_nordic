#!/usr/bin/env bash

source call_bashhelper
#---------------------------------------------------------------------------------------------------------
# Create help text
function Usage {
    cat <<USAGE

---------------------------------------------------------------------------------------------------
spinoza_nordic

Run NORDIC denoising on whole-brain functional data. Expects a BIDS-like folder structure with the
magnitude data in 'func' and the phase data in 'phase'. If phase data is not present, we'll attempt
a magnitude-only NORDIC process. If NORDIC is being run, we'll copy the 'func'-folder as 'no_nordic' 
folder to denote that not preprocessing has taken place, while keeping the data close. The NORDIC'ed 
data will be placed in 'func', without any special tags to avoid that fMRIPrep gets confused. How-
ever, it's likely you've produced the phase output with 'spinoza_scanner2bids', in which case the 
files will be named properly. Thus, the folder structure is expected to be like:

<dir_projects>
└── <project>
    └── sub-<subject>
        └── ses-<session>
            ├── fmap
            │   ├── sub-<subject>_ses-<session>_task-<task_id>_run-<run_id>_epi.json
            │   └── sub-<subject>_ses-<session>_task-<task_id>_run-<run_id>_epi.nii.gz
            ├── func
            │   ├── sub-<subject>_ses-<session>_task-<task_id>_run-<run_id>_bold.json
            │   └── sub-<subject>_ses-<session>_task-<task_id>_run-<run_id>_bold.nii.gz
            └── phase
                ├── sub-<subject>_ses-<session>_task-<task_id>_run-<run_id>_bold_ph.json
                └── sub-<subject>_ses-<session>_task-<task_id>_run-<run_id>_bold_ph.nii.gz

Usage:
  spinoza_nordic [options] <bids folder>

Arguments:
  -s <subject>        subject ID (e.g., 01). Can also be comma-separated list: 01,02,05
  -n <session>        session ID (e.g., 1, 2, or none
  --sge               submit individual NORDIC processes to the cluster for parallellization. If 
                      you do this, it's advised to have identifiable 'run-' flags in your filenames
                      so that the template file is not overwritten; this can cause problems. If you
                      do not have run identifiers in your filenames, please run serially. This flag
                      is inherited from 'master', so calling it there will pass on the flag here.
  <bids folder>       parent directory containing the sub-xxx folders for functional data. Can be 
                      e.g., DIR_DATA_HOME or DIR_DATA_HOME/derivatives/pymp2rage

Example:
  spinoza_nordic DIR_DATA_HOME                          # run for all subjects
  spinoza_nordic -s 001 -n 1 DIR_DATA_HOME              # run for specific subject/session
  spinoza_nordic --sge DIR_DATA_HOME                    # submit to cluster

---------------------------------------------------------------------------------------------------

USAGE
    exit 1
}

# Check for subject flag
job="bash"
smp=1
SGE=0
while getopts :-:s:n: argument
do
  case ${argument} in
    -)
      case "${OPTARG}" in
        sge)
          SGE=1
          ;;                                                                   
        *)
          if [ "$OPTERR" = 1 ] && [ "${optspec:0:1}" != ":" ]; then
            echo "Unknown option --${OPTARG}"
            exit 1
          fi
          ;;
      esac;;      
    s)  sub=${OPTARG}
          ;;
    n)  ses=${OPTARG}
          ;;     
  esac
done

if [[ $# -lt 1 ]] ; then
  Usage >&2
  exit 1
fi

INPUT=${@:$OPTIND:1}

if [[ -z ${sub} ]]; then
  # loop through subjects
  search="${INPUT}/${SUBJECT_PREFIX}*"
else
  # read specified subjects into array
  IFS=', ' read -r -a search <<< "${sub}"
  search=${search[@]}
  unset IFS
fi

#-----------------------------------------------------------------------------
# Start clock
#-----------------------------------------------------------------------------

echo
echo "==================================================================================================="
printf "NORDIC denoising of whole-brain data\n"
start=`date +%s`
start_date=`date`

printf "Started at ${start_date}\n"
echo "==================================================================================================="

#-----------------------------------------------------------------------------
# Run it
for subID in ${search}; do

  # collect subject name
  if [[ ! -z ${sub} ]]; then
    sub_name=${SUBJECT_PREFIX}${subID}
  else
    sub_name=$(basename ${subID})
  fi

  if [[ ! -z ${ses} ]]; then
    nr=`echo ${ses} | sed -e 's/^[[:space:]]*//'`
    base_path=${sub_name}/ses-${nr}
    base=${sub_name}_ses-${nr}
  else
    base_path=${sub_name}
    base=${sub_name}
  fi

  func_folder=${INPUT}/${base_path}/func
  tmp_folder=${INPUT}/${base_path}/no_nordic
  phase_folder=${INPUT}/${base_path}/phase

  echo
  echo "**************************************** Processing ${sub_name} ***************************************" 

  if [ ! -d ${func_folder} ]; then
    echo "ERROR in `basename ${0}`: could not find folder \"${func_folder}\""
    exit 1
  else
    echo "Make backup of \"func\" in \"no_nordic\""
    if [ -d ${tmp_folder} ]; then
      rm -r ${tmp_folder}
    fi
    cp -r ${func_folder} ${tmp_folder} 2>/dev/null
    rm -r ${func_folder}/*.nii.gz 2>/dev/null
  fi

  # check BOLD files
  IMGS=`find "${tmp_folder}" -type f \( -name "*bold.nii.gz" \) 2>/dev/null`
  IFS=$'\n' mag_imgs=($(sort <<<"${IMGS[*]}"))
  unset IFS

  if [[ -z ${mag_imgs} ]]; then
    echo "${sub_name}: could not find \"bold.nii.gz\"-images in \"${tmp_folder}\"?"
    exit 1
  fi

  # check if there's a phase directory
  if [[ -d ${phase_folder} ]]; then

    json_msg="Magnitude+phase"

    IMGS=`find "${phase_folder}" -type f \( -name "*bold_ph.nii.gz" \) 2>/dev/null`
    IFS=$'\n' phase_imgs=($(sort <<<"${IMGS[*]}"))
    unset IFS

    ct=0
    for ph_img in ${phase_imgs[@]}; do

      # get corresponding magnitude image
      mag_img=${mag_imgs[ct]}

      # decide on job execution
      if [[ ${SGE} -eq 1 ]]; then
        run_id=`run_id ${ph_img}`
        if [[ -z ${run_id} || ${run_id} -eq 0 ]]; then
          run_id=$((ct+1))
        fi

        job="qsub -q ${SGE_QUEUE_LONG} -wd ${DIR_LOGS} -pe smp ${smp} -N nordic${run_id}"
        if [ ! -d ${DIR_LOGS} ]; then
          mkdir -p ${DIR_LOGS}
        fi
      else
        echo "Running NORDIC on \"${mag_img}\" [phase]"
      fi

      # run if basenames of phase and magnitude match
      if [[ $(basename ${ph_img} _ph.nii.gz) == $(basename ${mag_img} .nii.gz) ]]; then
        out=${func_folder}/$(basename ${mag_img})
        ${job} ${DIR_SCRIPTS}/bin/call_nordic ${mag_img} ${ph_img} ${out}
      else
        echo "ERROR in `basename ${0}`: mismatch between \"$(basename ${ph_img} _ph.nii.gz)\" & \"$(basename ${mag_img} .nii.gz)\""
      fi

      # increment indexer
      ((ct++))
    done

  else
    # magnitude only
    json_msg="Magnitude only"
    for img in ${mag_imgs[@]}; do

      if [[ ${SGE} -eq 1 ]]; then
        run_id=`run_id ${img}`
        if [[ -z ${run_id} || ${run_id} -eq 0 ]]; then
          run_id=$((ct+1))
        fi

        job="qsub -q ${SGE_QUEUE_LONG} -wd ${DIR_LOGS} -pe smp ${smp} -N nordic${run_id}"
        if [ ! -d ${DIR_LOGS} ]; then
          mkdir -p ${DIR_LOGS}
        fi
      else
        echo "Running NORDIC on \"${img}\" [mag-only]"
      fi
      out=${func_folder}/$(basename ${mag_img})
      ${job} ${DIR_SCRIPTS}/bin/call_nordic -m ${img} ${img} ${out}
    done
  fi
  
  # add message to json files
  echo "Adding {\"Nordic\": \"${json_msg}\"} to json-files"
  for file in ${func_folder}/*.json; do
    call_json ${file} "Nordic" "${json_msg}"
  done

  # add message to json files
  echo "Adding {\"Nordic\": \"off\"} to original json-files"
  for file in ${tmp_folder}/*.json; do
    call_json ${file} "Nordic" "off"
  done

  # remove any left over unzipped files
  nii_files=`find ${func_folder} -type f -name "*.nii" 2>/dev/null`
  if [[ ! -z ${nii_files} ]]; then
    rm -r ${nii_files} 2>/dev/null
  fi

done

#-----------------------------------------------------------------------------
# Calculate time spent using 'let'
echo
echo "---------------------------------------------------------------------------------------------------"
end=`date +%s`
end_date=`date`
printf "Done at ${end_date}\n"

let deltatime=end-start
let hours=deltatime/3600
let minutes=(deltatime/60)%60
let seconds=deltatime%60
printf "Time spent: %d:%02d:%02d\n" ${hours} ${minutes} ${seconds}
echo "---------------------------------------------------------------------------------------------------"
