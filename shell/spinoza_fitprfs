#!/usr/bin/env bash

#---------------------------------------------------------------------------------------------------------
# check if there's is a setup file containing the major paths and source it if it exists
echo
source ${DIR_SCRIPTS}/shell/spinoza_setup
source call_bashhelper

#---------------------------------------------------------------------------------------------------------
# Create help text
function Usage {
    cat <<USAGE

---------------------------------------------------------------------------------------------------
spinoza_fitprfs

Wrapper for call_prf that does the pRF-fitting using the output from pybest and the package pRFpy. 
There's several options for design matrix cases (in order of priority):
  - Place a design-matrix file called 'vis_design.mat' in DIR_DATA_HOME/code
  - A directory with log-directories. A global search for a directory containing "Screenshots" is 
    done. If more directories are found and '--one_design' is specified, we'll take the first dir
    ectory
  - A directory with log-directories, but '--one_design' is NOT specified, meaning that each run 
    will get a separate design matrix. This can be useful if you have multiple conditions that have 
    different designs.

Usage:
  spinoza_fitprfs [options] <input dir> <output dir> <png dir>

Options:
  -c              list of values used for clipping of design matrix. Format must be [<top>,<bottom>,
                  <left>,<right>]. Negative values will be set to zero within 'linescanning.prf.
                  get_prfdesign'
  -m <model>      one of ['gauss','dog','css','norm'] is accepted, default = "gauss"
  -n <session>    session ID (e.g., 1, 2, or none)
  -o              delete existing file and re-run analysis fully. Even if 'model=norm', we'll over-
                  write the Gaussian parameters. If not specified, and 'model=norm' while Gaussian 
                  parameters already exist, we'll inject them into the DN-model.
  -s <subject>    subject ID (e.g., 01). Can also be comma-separated list: 01,02,05
  -t <task ID>    If you have mutiple tasks specified in TASK_SES1 or you just have multiple tasks and 
                  you want to run only one, specify the task name here ('task-rest' is ignored).
                  You can also specify multiple tasks if you want to bypass the setup file completely. 
                  In that case, use the format '-t <task1>,<task2>,<task3>'
  -x <constr>     String or list of constraints to use for the gaussian and extended stage. By default, 
                  we'll use trust-constr minimization for both stages, but you can speed up the exten-
                  ded models with L-BGFS. Note that if you want the same minimizer for both stages, you 
                  can use the '--tc' or '--bgfs' tags. This input specifically allows you to specify a 
                  list of different minimizers for each stage, e.g., trust-constr for Gaussian model, 
                  and L-BGFS for extended model. The format should be '-x "tc,bgfs"'
  --bgfs          use L-BGFS minimization for both the Gaussian as well as the extended model. Use 
                  the '-x'flag if you want different minimizers for both stages   
  --grid          only run grid fit, skip iterative fit
  --hrf           fit the HRF during pRF-fitting. See 'call_prf' for more information
  --local         run locally even though we have SGE available.
  --multi_design  specifies that for all runs in the dataset have run-/task-specific screenshot di-
                  rectories. This requires that the directory names you saved must match your naming 
                  scheme of functional files as we'll match on run-/task-ID
  --no_clip       ensures that the design matrix is NOT clipped, despite the possible presence of 
                  screen delimiter files
  --no_fit        Stop the process before fitting, right after saving out averaged data. This was use-
                  ful for me to switch to percent-signal change without requiring a re-fit.
  --no_grid       Don't save out gridsearch parameters
  --no_bounds     Turn off grid bounds; sometimes parameters fall outside the grid parameter bounds, 
                  causing 'inf' values. This is especially troublesome when fitting a single time-
                  course. If you trust your iterative fitter, you can turn off the bounds and let 
                  the iterative take care of the parameters
  --raw           use the raw, un-zscore'd output from pybest, rather than percent signal change
  --tc            use trust-constr minimization for both the Gaussian as well as the extended model. 
                  Use the '-x' flag if you want different minimizers for both stages
  --zscore        use the zscore'd output from pybest, rather than percent signal change. If not spe-
                  cified, percent signal change is implemented as follows:
                    psc = signals*100/(mean(signals)) - median(signals_without_stimulus)
  --v1|--v1       only fit voxels from ?.V1/2_exvivo.thresh.label; the original dimensions will be 
                  maintained, but timecourses outside of the ROI are set to zero
    
Arguments:
  <input dir>     base input directory with pybest data (e.g., 'DIR_DATA_DERIV/pybest'). You can also 
                  point to the fmriprep-folder, in which case the gifti's of 'fsnative' will be used.
  <output dir>    base output directory for prf data (e.g., 'DIR_DATA_DERIV/prf')
  <png dir>       base path of where sourcedata of subjects live. In any case, the subject ID will be
                  appended to this path (if applicable, so will session ID). Inside THAT directory, 
                  we'll search for directories with 'Screenshots'. So, if you specify DIR_DATA_SOURCE 
                  for 'sub-005' and 'ses-1', we'll search in DIR_DATA_SOURCE/sub-005/ses-1/* for di-
                  rectories with "Screenshots". If multiple directories are found, it depends on the 
                  options which directory is used: if --multi_design is specified, each directory will 
                  be matched with its corresponding functional run. If not, we'll take the 1st direc-
                  tory in the list.

Eample:
  spinoza_fitprfs DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE
  spinoza_fitprfs -s 001 -n 1 DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE
  spinoza_fitprfs --multi_design DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE
  spinoza_fitprfs -g -l DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE
  spinoza_fitprfs -o DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE

---------------------------------------------------------------------------------------------------

USAGE
    exit 1
}

# Check for subject & session flags
OW=0
OW_flag=""
run_locally=0
grid_flag=""
multi_design=0
fit_hrf=""
zscore_flag=""
raw_flag=""
verb_flag=""
clip_flag=""
clip=1
use_constr="--tc"
fit_flag=""
cut_vols=""
lbl_flag=""
save_grid=""
bounds_flag=""
while getopts :-:los:n:m:t:x:c:v: argument
do
  case ${argument} in
    -)
      case "${OPTARG}" in
        multi_design)
          multi_design=1
          ;;           
        hrf)
          fit_hrf="--hrf"
          ;;           
        zscore)
          zscore_flag="--zscore"
          ;;  
        raw)
          raw_flag="--raw"
          ;;   
        verbose)
          verb_flag="--verbose"
          ;;
        no_clip)
          clip=0
          ;;    
        local)
          run_locally=1
          ;;       
        grid)
          grid_flag="--grid"
          ;;
        tc)
          use_constr="--tc"
          ;;
        bgfs)
          use_constr="--bgfs"
          ;;    
        no_fit)
          fit_flag="--no_fit"
          ;;      
        no_grid)
          save_grid="--no_grid"
          ;;            
        v1)
          lbl_flag="--v1"
          ;;
        v2)
          lbl_flag="--v2"
          ;;      
        no_bounds)
          bounds_flag="--no_bounds"
          ;;                
        *)
          if [ "$OPTERR" = 1 ] && [ "${optspec:0:1}" != ":" ]; then
            echo "Unknown option --${OPTARG}"
            exit 1
          fi
          ;;
      esac;;    
    s)  sub=${OPTARG}
          ;;
    n)  ses=${OPTARG}
          ;;
    m)  model=${OPTARG}
          ;;
    t)  task_ID=${OPTARG}
          ;;                                       
    o)  OW=1
        OW_flag="--overwrite"
          ;;
    c)  clipper=${OPTARG}
          ;;     
    x)  use_constr="--constr [${OPTARG[@]}]"
          ;;
    v)  cut_vols="--cut_vols ${OPTARG[@]}"
          ;;          
  esac
done

if [[ $# -lt 3 ]] ; then
  Usage >&2
  exit 1
fi

INPUT=${@:$OPTIND:1}
OUTPUT=${@:$OPTIND+1:1}
PNG=${@:$OPTIND+2:1}

if [[ -z ${sub} ]]; then
  # loop through subjects
  search="${INPUT}/${SUBJECT_PREFIX}*"
else
  # read specified subjects into array
  IFS=', ' read -r -a search <<< "${sub}"
  search=${search[@]}
  unset IFS
fi

#-----------------------------------------------------------------------------
# Start clock
#-----------------------------------------------------------------------------

echo "==================================================================================================="
printf "pRF-FITTING WITH pRFpy\n"
start=`date +%s`
start_date=`date`

printf "Started at ${start_date}\n"
echo "==================================================================================================="

#-----------------------------------------------------------------------------
# Run it
for subID in ${search}; do

  # collect subject name
  if [[ ! -z ${sub} ]]; then
    sub_name=${SUBJECT_PREFIX}${subID}
    sub_id=${subID}
  else
    sub_name=$(basename ${subID})
    sub_id=`get_id ${sub_name} ${SUBJECT_PREFIX}`
  fi

  if [[ ! -z ${ses} ]]; then
    nr=`echo ${ses} | sed -e 's/^[[:space:]]*//'`
    base_path=${sub_name}/ses-${nr}
    base=${sub_name}_ses-${nr}
  else
    base_path=${sub_name}
    base=${sub_name}
  fi

  input_dir=${INPUT}/${base_path}
  prf_dir=${OUTPUT}/${base_path}
  png_dir=${PNG}/${base_path}

  # check if we got model specification
  if [[ -z ${model} ]]; then
    use_model="gauss"
  else
    if [[ ${model,,} == "gauss" || ${model,,} == "css" || ${model,,} == "dog" || ${model,,} == "norm" ]]; then
      use_model=${model,,}
    else
      echo "ERROR in `basename ${0}`: model specified was \"${model}\". Please use \"gauss\", \"dog\", \"css\", or \"norm\"."
      exit 1
    fi
  fi

  if [[ ! -d ${prf_dir} ]]; then
    mkdir -p ${prf_dir}
  fi

  # look for parameter file
  if [[ ${grid_only} -eq 1 ]]; then
    txt="grid-fit only with model ${use_model}"
    stage="stage-grid"
  else
    txt="iter-fit with model ${use_model}" 
    stage="stage-iter"
  fi

  # check if input is pybest or fmriprep
  if [[ $(basename ${INPUT}) == "pybest" ]]; then
    if [[ ! -z ${zscore_flag} ]]; then
      use_dir="denoising" # directly use pybest output (= zscored)
    else
      use_dir="unzscored" # we requested percent signal change; use output from call_unzscore
    fi
    full_input=${input_dir}/${use_dir}
  elif [[ $(basename ${INPUT}) == "fmriprep" ]]; then
    full_input=${input_dir}/func
  else
    full_input=${input_dir}
  fi

  # do stuff if input directory exists
  if [[ -d ${full_input} ]]; then

    echo
    echo "**************************************** Processing ${sub_name} ***************************************"
    
    # fetch PNG-directories, sort, and save in array
    PNG_UNSORTED=`find ${png_dir} -type d \( -name "*Screenshots*" \) 2>/dev/null`
    IFS=$'\n' PNGS_DIR=($(sort <<<"${PNG_UNSORTED[*]}"))
    unset IFS    
    
    echo "Running pRF-analysis; ${txt}"

    # check if we got custom specified task ID; otherwise loop through task IDs from setup file
    if [[ ! -z ${task_ID} ]]; then
      IFS=', ' read -r -a search_tasks <<< "${task_ID}"
      unset IFS
    else
      search_tasks=${TASK_SES1[@]}
    fi

    # loop through tasks
    for task in ${search_tasks[@]}; do

      # Check if we should overwrite file
      if [[ ! -z ${lbl_flag} ]]; then
        if [[ ${lbl_flag} == *"v1"* ]]; then
          roi="V1"
        elif [[ ${lbl_flag} == *"v2"* ]]; then
          roi="V2"
        else
          echo "ERROR in `basename ${0}`: the flag '${lbl_flag}' was specified, but there is only support for '--v1'/'--v2'"
          exit 1
        fi

        prf_params=`find ${prf_dir} -type f \( -name "*${use_model}*" -and -name "*roi-${roi}*" -and -name "*${stage}*" -and -name "*task-${task}*" -and -name "*prf_params.pkl" \) 2>/dev/null`
      else
        prf_params=`find ${prf_dir} -type f \( -name "*${use_model}*" -and -name "*${stage}*" -and -name "*task-${task}*" -and -name "*prf_params.pkl" \) 2>/dev/null`
      fi
      
      if [[ ${OW} -eq 1 ]]; then
        if [[ -f ${prf_params} ]]; then
          rm -r ${prf_params}
        fi
      fi

      # run stuff if file doesn't exist
      if [[ ! -f ${prf_params} ]] || [[ ! -z ${fit_flag} ]]; then

        # exclude rest as task
        if [[ ${task} != "rest" ]]; then

          echo "Dealing with task-ID: ${task}"
          # decide on design matrix for tasks in TASK_SES1
          if [[ ${multi_design} -eq 0 ]]; then

            if [[ ! -z ${task_ID} ]]; then
              echo
              echo "---------------------------------------------------------------------------------------------------"
              echo "WARNING in `basename ${0}`: custom task \"${task_ID}\" was/were specified, but \"--multi_design\"-flag omitted."
              echo "This may result in selection of the wrong png-folder. Please rerun with \"--multi_design\""
              exit 2
            fi

            if [[ -f ${DIR_DATA_HOME}/code/design_task-${task}.mat ]]; then
              echo "Creating symlink to ${PROJECT}/code/design_task-${task}.mat"
              ln -s ${DIR_DATA_HOME}/code/design_task-${task}.mat ${prf_dir}/design_task-${task}.mat
              use_pngdir=${DIR_DATA_HOME}/code/design_task-${task}.mat
            elif [[ -f ${prf_dir}/design_task-${task}.mat ]]; then
              use_pngdir=${prf_dir}/design_task-${task}.mat
            else
              use_pngdir=${PNGS_DIR[0]}

              # check if directory contains png-files
              if [[ -z `find ${use_pngdir} -type f \( -name "*.png" \) 2>/dev/null` ]]; then
                echo "ERROR in `basename ${0}`: no *.png-files in \"${use_pngdir}\""
                continue
              fi
            fi
            
          else
            # how cool; list comprehension-like structure in bash
            # https://stackoverflow.com/a/6721137
            task_dirs=($(for x in ${PNGS_DIR[@]}; do if [[ ${x} == *"task-${task}"* ]]; then echo ${x}; fi done))
            if [[ ! -z ${task_dirs} ]]; then
              use_pngdir=${task_dirs[0]}

              # check if directory contains png-files
              if [[ -z `find ${use_pngdir} -type f \( -name "*.png" \) 2>/dev/null` ]]; then
                echo "ERROR in `basename ${0}`: no *.png-files in \"${use_pngdir}\""
                continue
              fi
            else
              echo "ERROR in `basename ${0}`: could not find \"task-${task}\" folders"
              continue
            fi
          fi

          echo "Using \"${use_pngdir}\" for design matrix"

          # check if we have screen delimiter file (should be json file) if clip=1 (can be set to 0 by --no_clip)
          if [[ ${clip} -eq 1 ]]; then

            # check if we got manual clip information
            if [[ -z ${clipper} ]]; then

              if [[ -d ${use_pngdir} ]]; then
                # check first if we have a json file
                screen_=`find $(dirname ${use_pngdir}) -type f \( -name "*screen.json" \) 2>/dev/null`
                if [[ -f ${screen_} ]]; then
                  clip_flag="--clip ${screen_}"
                else
                  # if not, check if we have yml file (should contain "screen_delim"-key)
                  screen_=`find $(dirname ${use_pngdir}) -type f \( -name "*.yml" \) 2>/dev/null`
                  if [[ -f ${screen_} ]]; then

                    # check if we have "screen_delim"-key in yml file
                    if [[ ! -z `grep "screen_delim" ${screen_}` ]]; then
                      clip_flag="--clip ${screen_}"
                    else
                      clip_flag=""
                    fi
                    
                  else
                    clip_flag=""
                  fi
                fi
              fi
            else
              clip_flag="--clip ${clipper}"
            fi
          fi

          # decide how to execute the process
          if [[ ${PLACE} != "SGE" ]]; then
            job="python"
          else
            if [[ ${run_locally} -eq 0 ]]; then
              job="qsub -q ${SGE_QUEUE_LONG} -pe smp 1 -wd ${prf_dir} -N s${sub_id}_${task}"
            elif [[ ${run_locally} -eq 1 ]]; then
              job="python"
            else
              echo "ERROR in `basename ${0}`: invalid option \"${run_locally}\". Must be '0' or '1'"
              exit 1
            fi
          fi
  
          # define call to call_prf
          export DISPLAY=:0
          ${job} ${DIR_SCRIPTS}/bin/call_prf ${grid_flag} ${fit_hrf} ${clip_flag} \
            -s ${sub_id} \
            -n ${nr} \
            -t ${task} \
            -o ${prf_dir} \
            -i ${full_input} \
            -p ${use_pngdir} \
            -m ${use_model} \
            -u ${PYBEST_SPACE} \
            ${save_grid} \
            ${lbl_flag} \
            ${zscore_flag} \
            ${raw_flag} \
            ${verb_flag} \
            ${OW_flag} \
            ${use_constr} \
            ${fit_flag} \
            ${cut_vols} \
            ${bounds_flag}
          
          if [[ $? -ne 0 ]]; then
            echo "ERROR in `basename ${0}`: call_prf did not execute cleanly"
            exit 1
          fi

        fi

      else
        echo "`basename ${prf_params}` file exists"
        continue
      fi
      
    done

  else
    echo "${sub_name}: Directory \"${full_input}\" not valid."
  fi

done

#-----------------------------------------------------------------------------
# Calculate time spent using 'let'
echo
echo "---------------------------------------------------------------------------------------------------"
end=`date +%s`
end_date=`date`
printf "Done at ${end_date}\n"

let deltatime=end-start
let hours=deltatime/3600
let minutes=(deltatime/60)%60
let seconds=deltatime%60
printf "Time spent: %d:%02d:%02d\n" ${hours} ${minutes} ${seconds}
echo "---------------------------------------------------------------------------------------------------"
