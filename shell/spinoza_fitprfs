#!/usr/bin/env bash

#---------------------------------------------------------------------------------------------------------
# check if there's is a setup file containing the major paths and source it if it exists
echo
source ${SETUP_FILE}
source call_bashhelper

#---------------------------------------------------------------------------------------------------------
# Create help text
function Usage {
    cat <<USAGE

---------------------------------------------------------------------------------------------------
spinoza_fitprfs

Wrapper for call_prf that does the pRF-fitting using the output from pybest and the package pRFpy. 
There's several options for design matrix cases (in order of priority):
  - Place a design-matrix file called 'design_task-<TASK_NAME>.mat' in DIR_DATA_HOME/code
  - A directory with log-directories. A global search for a directory containing "Screenshots" is 
    done. If more directories are found and '--one_design' is specified, we'll take the first dir
    ectory
  - A directory with log-directories, but '--one_design' is NOT specified, meaning that each run 
    will get a separate design matrix. This can be useful if you have multiple conditions that have 
    different designs.

Usage:
  spinoza_fitprfs [options] <input dir> <output dir> <png dir>

Options:
  -c              list of values used for clipping of design matrix. Format must be [<top>,<bottom>,
                  <left>,<right>]. Negative values will be set to zero within 'linescanning.prf.
                  get_prfdesign'
  -f <n_folds>    if your pRF experiment contains multiple equal sequences, you can use this flag
                  to perform within-run averaging before percent-changing in call_prf. This should
                  be in concert with number of volumes removed from the beginning of the timeseries                  
  -k <kwargs>     specify a file with additional arguments, similar to FreeSurfer's expert options.
                  See linescanning/misc/prf_options for an example. Please make sure you have a 
                  final empty white space at the end of the file, otherwise the parser gets confu-
                  sed. For VSCode: https://stackoverflow.com/a/44704969.
  -m <model>      one of ['gauss','dog','css','norm'] is accepted, default = "gauss"
  -n <session>    session ID (e.g., 1, 2, or none)
  -o              delete existing file and re-run analysis fully. Even if 'model=norm', we'll over-
                  write the Gaussian parameters. If not specified, and 'model=norm' while Gaussian 
                  parameters already exist, we'll inject them into the DN-model.
  -s <subject>    subject ID (e.g., 01). Can also be comma-separated list: 01,02,05
  -t <task ID>    If you have mutiple tasks specified in TASK_SES1 or you just have multiple tasks and 
                  you want to run only one, specify the task name here ('task-rest' is ignored).
                  You can also specify multiple tasks if you want to bypass the setup file completely. 
                  In that case, use the format '-t <task1>,<task2>,<task3>'
  -x <constr>     String or list of constraints to use for the gaussian and extended stage. By default, 
                  we'll use trust-constr minimization for both stages, but you can speed up the exten-
                  ded models with L-BGFS. Note that if you want the same minimizer for both stages, you 
                  can use the '--tc' or '--bgfs' tags. This input specifically allows you to specify a 
                  list of different minimizers for each stage, e.g., trust-constr for Gaussian model, 
                  and L-BGFS for extended model. The format should be '-x "tc,bgfs"'
  -j <n_jobs>     number of jobs to parallellize over; default is 10
  -q <queue>      submit jobs to a specific queue. Defaults to SGE_QUEUE_LONG in spinoza_setup
  -r <TR>         set repetition time (TR) manually. Defaults to 1.5 if input != gifti's. Otherwise
                  we'll read it from gifti-files with 'dataset.ParseGiftiFile'
  -v <n_vols>     number of volumes to cut from the beginning of the timeseries (default = None)
  --bgfs          use L-BGFS minimization for both the Gaussian as well as the extended model. Use 
                  the '-x'flag if you want different minimizers for both stages
  --bold          re-calculate the BOLD timecourses; otherwise use existing '*hemi-LR_desc-avg_bold.npy'   
  --fsaverage     overwrite PYBEST_SPACE-variable and use FSAverage for fitting (see your setup file)
  --fsnative      overwrite PYBEST_SPACE-variable and use FSNative for fitting (see your setup file)                  
  --grid          only run grid fit, skip iterative fit
  --no_hrf        do NOT fit the HRF during pRF-fitting. See 'call_prf' for more information
  --separate_hrf  fit the HRF in two stages. See 'call_prf' for more information
  --local         run locally even though we have SGE available.
  --merge_ses     average pRF data from all sessions
  --multi_design  specifies that for all runs in the dataset have run-/task-specific screenshot di-
                  rectories. This requires that the directory names you saved must match your naming 
                  scheme of functional files as we'll match on run-/task-ID
  --no_clip       ensures that the design matrix is NOT clipped, despite the possible presence of 
                  screen delimiter files
  --no_fit        Stop the process before fitting, right after saving out averaged data. This was use-
                  ful for me to switch to percent-signal change without requiring a re-fit.
  --save_grid     Save out gridsearch parameters
  --no_bounds     Turn off grid bounds; sometimes parameters fall outside the grid parameter bounds, 
                  causing 'inf' values. This is especially troublesome when fitting a single time-
                  course. If you trust your iterative fitter, you can turn off the bounds and let 
                  the iterative take care of the parameters
  --raw           use the raw, un-zscore'd output from pybest, rather than percent signal change
  --refit         refit existing data; uses a simplified call to linescanning.prf.pRFmodelFitting 
                  using call_prfrefit
  --tc            use trust-constr minimization for both the Gaussian as well as the extended model. 
                  Use the '-x' flag if you want different minimizers for both stages
  --zscore        use the zscore'd output from pybest, rather than percent signal change. If not spe-
                  cified, percent signal change is implemented as follows:
                    psc = signals*100/(mean(signals)) - median(signals_without_stimulus)
  --v1|--v1       only fit voxels from ?.V1/2_exvivo.thresh.label; the original dimensions will be 
                  maintained, but timecourses outside of the ROI are set to zero
    
Arguments:
  <input dir>     base input directory with pybest data (e.g., 'DIR_DATA_DERIV/pybest'). You can also 
                  point to the fmriprep-folder, in which case the gifti's of 'fsnative' will be used.
  <output dir>    base output directory for prf data (e.g., 'DIR_DATA_DERIV/prf')
  <png dir>       base path of where sourcedata of subjects live. In any case, the subject ID will be
                  appended to this path (if applicable, so will session ID). Inside THAT directory, 
                  we'll search for directories with 'Screenshots'. So, if you specify DIR_DATA_SOURCE 
                  for 'sub-005' and 'ses-1', we'll search in DIR_DATA_SOURCE/sub-005/ses-1/* for di-
                  rectories with "Screenshots". If multiple directories are found, it depends on the 
                  options which directory is used: if --multi_design is specified, each directory will 
                  be matched with its corresponding functional run. If not, we'll take the 1st direc-
                  tory in the list.

Models for pRF fitting:
  --gauss         run standard Gaussian model (default) [Dumoulin & Wandell, 2008]
  --dog           run difference-of-gaussian model (suppression) [Zuiderbaan, et al. 2013]
  --css           run compressive spatial summation model (compression) [Kay, et al. 2013]
  --norm          run divisive normalization model (suppresion+compression) [Aqil, et al. 2021]

Eample:
  spinoza_fitprfs DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE
  spinoza_fitprfs -s 001 -n 1 DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE
  spinoza_fitprfs --multi_design DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE
  spinoza_fitprfs -g -l DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE
  spinoza_fitprfs -o DIR_DATA_DERIV/prf DIR_DATA_DERIV/pybest DIR_DATA_SOURCE

---------------------------------------------------------------------------------------------------

USAGE
    exit 1
}

# Check for subject & session flags
OW=0
OW_flag=""
run_locally=0
grid_flag=""
multi_design=0
fit_hrf=""
zscore_flag=""
raw_flag=""
verb_flag=""
clip_flag=""
clip=1
use_constr="--tc"
fit_flag=""
cut_vols=""
lbl_flag=""
save_grid=""
bounds_flag=""
merge_flag=""
jobs_flag=""
model="gauss"
n_jobs=5
kwargs_file=""
tr_flag=""
use_space=${PYBEST_SPACE}
refit_data=0
n_pix=100
redo_bold=""
folds_flag=""
skip_flag=""
trans_flag=""
while getopts :-:los:n:m:t:x:c:v:j:k:q:r:p:f: argument
do
  case ${argument} in
    -)
      case "${OPTARG}" in
        multi_design)
          multi_design=1
          ;;           
        no_hrf)
          fit_hrf="--no_hrf"
          ;;  
        separate_hrf)
          fit_hrf="--separate_hrf"
          ;;             
        gauss)
          model="gauss"
          ;;  
        dog)
          model="dog"
          ;;   
        css)
          model="css"
          ;;  
        norm)
          model="norm"
          ;;       
        abc)
          model="abc"
          ;;     
        abd)
          model="abd"
          ;;                                                        
        zscore)
          zscore_flag="--zscore"
          ;;  
        raw)
          raw_flag="--raw"
          ;;   
        verbose)
          verb_flag="--verbose"
          ;;
        no_clip)
          clip=0
          ;;    
        local)
          run_locally=1
          ;;       
        grid)
          grid_flag="--grid"
          ;;
        tc)
          use_constr="--tc"
          ;;
        bgfs)
          use_constr="--bgfs"
          ;;    
        no_fit)
          fit_flag="--no_fit"
          ;;      
        save_grid)
          save_grid="--save_grid"
          ;;            
        v1)
          lbl_flag="--v1"
          ;;
        v2)
          lbl_flag="--v2"
          ;;      
        no_bounds)
          bounds_flag="--no_bounds"
          ;;     
        merge_ses)
          merge_flag="--merge_ses"
          ses_id="avg"
          ;;        
        fsaverage)
          use_space="fsaverage"
          ;; 
        fsnative)
          use_space="fsnative"
          ;;                 
        refit)
          refit_data=1
          ;;  
        bold)
          redo_bold="--bold"
          ;;        
        skip_settings)
          skip_flag="--skip_settings"
          ;;     
        transpose)
          trans_flag="--transpose"
          ;;                                              
        *)
          if [ "$OPTERR" = 1 ] && [ "${optspec:0:1}" != ":" ]; then
            echo "Unknown option --${OPTARG}"
            exit 1
          fi
          ;;
      esac;;    
    s)  sub=${OPTARG}
          ;;
    n)  ses=${OPTARG}
          ;;
    m)  model=${OPTARG}
          ;;
    t)  task_ID=${OPTARG}
          ;;                                       
    o)  OW=1
        OW_flag="--overwrite"
          ;;
    c)  clipper=${OPTARG}
          ;; 
    p)  n_pix=${OPTARG}
          ;;          
    j)  n_jobs=${OPTARG}
          ;;               
    x)  use_constr="--constr [${OPTARG[@]}]"
          ;;
    v)  cut_vols="--cut_vols ${OPTARG[@]}"
          ;;        
    k)  kwargs_file="--kwargs ${OPTARG}"
          ;;       
    q)  SGE_QUEUE=${OPTARG}
          ;;  
    r)  tr_flag="--tr ${OPTARG}"
          ;;       
    f)  folds_flag="--folds ${OPTARG}"
          ;;                                    
  esac
done

if [[ $# -lt 3 ]] ; then
  Usage >&2
  exit 1
fi

INPUT=${@:$OPTIND:1}
OUTPUT=${@:$OPTIND+1:1}
PNG=${@:$OPTIND+2:1}

if [[ -z ${sub} ]]; then
  # loop through subjects
  search="${INPUT}/${SUBJECT_PREFIX}*"
else
  # read specified subjects into array
  IFS=', ' read -r -a search <<< "${sub}"
  search=${search[@]}
  unset IFS
fi

#-----------------------------------------------------------------------------
# Start clock
#-----------------------------------------------------------------------------

echo "==================================================================================================="
printf "pRF-FITTING WITH pRFpy\n"
start=`date +%s`
start_date=`date`

printf "Started at ${start_date}\n"
echo "==================================================================================================="

#-----------------------------------------------------------------------------
# Run it
for subID in ${search}; do

  # collect subject name
  if [[ ! -z ${sub} ]]; then
    sub_name=${SUBJECT_PREFIX}${subID}
    sub_id=${subID}
  else
    sub_name=$(basename ${subID})
    sub_id=`get_id ${sub_name} ${SUBJECT_PREFIX}`
  fi

  if [[ ! -z ${ses} ]]; then
    nr=`echo ${ses} | sed -e 's/^[[:space:]]*//'`
    ses_id="ses-${nr}"
    base_path=${sub_name}/${ses_id}
    base=${sub_name}_${ses_id}
  else
    base_path=${sub_name}
    base=${sub_name}
  fi

  # give path to subject root if merge session = True
  if [[ -z ${merge_flag} ]]; then
    input_dir=${INPUT}/${base_path}
    prf_dir=${OUTPUT}/${base_path}
  else
    input_dir=${INPUT}/${sub_name}
    prf_dir=${OUTPUT}/${sub_name}
  fi

  png_dir=${PNG}/${sub_name}

  # check if we got model specification
  if [[ -z ${model} ]]; then
    use_model="gauss"
  else
    allowed_models=("gauss" "css" "dog" "norm" "abc" "abd")
    # https://stackoverflow.com/a/15394738
    if [[ " ${allowed_models[*]} " =~ " ${model} " ]]; then
      use_model=${model,,}
    else
      echo "ERROR in `basename ${0}`: model specified was \"${model}\". Please use \"gauss\", \"dog\", \"css\", or \"norm\"."
      exit 1
    fi
  fi

  # look for parameter file
  if [[ ${grid_only} -eq 1 ]]; then
    txt="grid-fit only with model ${use_model}"
    stage="stage-grid"
  else
    txt="iter-fit with model ${use_model}" 
    stage="stage-iter"
  fi

  # check if input is pybest or fmriprep
  if [[ $(basename ${INPUT}) == "pybest" ]]; then
    if [[ ! -z ${zscore_flag} ]]; then
      use_dir="denoising" # directly use pybest output (= zscored)
    else
      use_dir="unzscored" # we requested percent signal change; use output from call_unzscore
    fi

    if [[ -z ${merge_flag} ]]; then 
      full_input=${input_dir}/${use_dir}
      pyb_flag=""
    else
      full_input=${input_dir}
      pyb_flag="--pyb_type ${use_dir}"
    fi
  elif [[ $(basename ${INPUT}) == "fmriprep" ]]; then
    # internally, call_prf uses utils.FindFiles, which searches for files recursively. No futher addition is required
    full_input=${input_dir}
  fi

  # do stuff if input directory exists
  if [[ -d ${full_input} || ${refit_data} -eq 1 ]]; then

    echo
    echo "**************************************** Processing ${sub_name} ***************************************"

    if [[ ! -d ${prf_dir} ]]; then
      mkdir -p ${prf_dir}
    fi

    # fetch PNG-directories, sort, and save in array
    PNG_UNSORTED=`find ${png_dir} -type d \( -name "*Screenshots*" \) 2>/dev/null`
    IFS=$'\n' PNGS_DIR=($(sort <<<"${PNG_UNSORTED[*]}"))
    unset IFS    
    
    echo "Running pRF-analysis; ${txt}"

    # check if we got custom specified task ID; otherwise loop through task IDs from setup file
    if [[ ! -z ${task_ID} ]]; then
      IFS=', ' read -r -a search_tasks <<< "${task_ID}"
      unset IFS
    else
      search_tasks=${TASK_SES1[@]}
    fi

    # loop through tasks
    for task in ${search_tasks[@]}; do

      # Check if we should overwrite file
      if [[ ! -z ${lbl_flag} ]]; then
        if [[ ${lbl_flag} == *"v1"* ]]; then
          roi="V1"
        elif [[ ${lbl_flag} == *"v2"* ]]; then
          roi="V2"
        else
          echo "ERROR in `basename ${0}`: the flag '${lbl_flag}' was specified, but there is only support for '--v1'/'--v2'"
          exit 1
        fi

        prf_params=`find ${prf_dir} -type f \( -name "*${use_model}*" -and -name "*roi-${roi}*" -and -name "*${stage}*" -and -name "*task-${task}*" -and -name "*prf_params.pkl" \) 2>/dev/null`
      else
        prf_params=`find ${prf_dir} -type f \( -name "*${use_model}*" -and -name "*${stage}*" -and -name "*task-${task}*" -and -name "*prf_params.pkl" -and -not -name "*roi-*" \) 2>/dev/null`
      fi
      
      if [[ ${OW} -eq 1 ]]; then
        if [[ -f ${prf_params} ]]; then
          rm -r ${prf_params}
        fi
      fi

      # run stuff if file doesn't exist
      if [[ ! -f ${prf_params} ]] || [[ ! -z ${fit_flag} ]] || [[ ${refit_data} -eq 1 ]]; then

        # exclude rest as task
        if [[ ${task} != "rest" ]]; then

          echo "Dealing with task-ID: ${task}"

          # decide on design matrix for tasks in TASK_SES1
          if [[ ${multi_design} -eq 0 ]]; then

            if [[ ! -z ${task_ID} ]]; then
              echo
              echo "---------------------------------------------------------------------------------------------------"
              echo "WARNING in `basename ${0}`: custom task \"${task_ID}\" was/were specified, but \"--multi_design\"-flag omitted."
              echo "This may result in selection of the wrong png-folder. Please rerun with \"--multi_design\""
              exit 2
            fi

            if [[ -f ${DIR_DATA_HOME}/code/design_task-${task}.mat ]]; then
              echo "Creating symlink to ${PROJECT}/code/design_task-${task}.mat"
              ln -s ${DIR_DATA_HOME}/code/design_task-${task}.mat ${prf_dir}/design_task-${task}.mat 2>/dev/null
              use_pngdir=${DIR_DATA_HOME}/code/design_task-${task}.mat
            elif [[ -f ${prf_dir}/design_task-${task}.mat ]]; then
              use_pngdir=${prf_dir}/design_task-${task}.mat
            else
              if [[ ! -z ${PNGS_DIR} ]]; then
                use_pngdir=${PNGS_DIR[0]}
              else
                echo
                echo "---------------------------------------------------------------------------------------------------"
                echo "ERROR in `basename ${0}`: could not find png's in \"${png_dir}\""
                echo "Some solutions could be:"
                echo " - Create \"${DIR_DATA_HOME}/code/design_task-${task}.mat\""
                echo " - Create \"${prf_dir}/design_task-${task}.mat\""
                echo " - Put directories containing \"Screenshots\"-directory in \"${png_dir}\""
                exit 1
              fi

              # check if directory contains png-files
              if [[ -z `find ${use_pngdir} -type f \( -name "*.png" \) 2>/dev/null` ]]; then
                echo "ERROR in `basename ${0}`: no *.png-files in \"${use_pngdir}\""
                continue
              fi
            fi
            
          else
            # how cool; list comprehension-like structure in bash
            # https://stackoverflow.com/a/6721137
            if [[ ! -z ${PNGS_DIR} ]]; then
              task_dirs=($(for x in ${PNGS_DIR[@]}; do if [[ ${x} == *"task-${task}"* ]]; then echo ${x}; fi done))
              if [[ ! -z ${task_dirs} ]]; then
                use_pngdir=${task_dirs[0]}

                # check if directory contains png-files
                if [[ -z `find ${use_pngdir} -type f \( -name "*.png" \) 2>/dev/null` ]]; then
                  echo "ERROR in `basename ${0}`: no *.png-files in \"${use_pngdir}\""
                  continue
                fi
              else
                echo "ERROR in `basename ${0}`: could not find \"task-${task}\" folders"
                continue
              fi
            else
              echo
              echo "---------------------------------------------------------------------------------------------------"
              echo "ERROR in `basename ${0}`: could not find png's in \"${png_dir}\""
              echo "Some solutions could be:"
              echo " - Create \"${DIR_DATA_HOME}/code/design_task-${task}.mat\""
              echo " - Create \"${prf_dir}/design_task-${task}.mat\""
              echo " - Put directories containing \"Screenshots\"-directory in \"${png_dir}\""
              exit 1
            fi
          fi

          echo "Using \"${use_pngdir}\" for design matrix"

          # check if we have screen delimiter file (should be json file) if clip=1 (can be set to 0 by --no_clip)
          if [[ ${clip} -eq 1 ]]; then

            # check if we got manual clip information
            if [[ -z ${clipper} ]]; then

              if [[ -d ${use_pngdir} ]]; then
                # check first if we have a json file
                screen_=`find $(dirname ${use_pngdir}) -type f \( -name "*screen.json" \) 2>/dev/null`
                if [[ -f ${screen_} ]]; then
                  clip_flag="--clip ${screen_}"
                else
                  # if not, check if we have yml file (should contain "screen_delim"-key)
                  screen_=`find $(dirname ${use_pngdir}) -type f \( -name "*.yml" \) 2>/dev/null`
                  if [[ -f ${screen_} ]]; then

                    # check if we have "screen_delim"-key in yml file
                    if [[ ! -z `grep "screen_delim" ${screen_}` ]]; then
                      clip_flag="--clip ${screen_}"
                    else
                      clip_flag=""
                    fi
                    
                  else
                    clip_flag=""
                  fi
                fi
              fi
            else
              clip_flag="--clip ${clipper}"
            fi
          fi

          # decide how to execute the process
          if [[ ${refit_data} -eq 0 ]]; then
            script_name="call_prf"
            bold_flag=""
            dm_flag=""
            par_flag=""
          else
            script_name="call_refit"

            # check bold file/ design matrix
            bold_file=`find ${prf_dir} -type f \( -name "*hemi-LR_*" -and -name "*avg_bold.npy" \) 2>/dev/null`
            dm_file=${prf_dir}/design_task-${task}.mat

            if [[ ! -f ${bold_file} ]]; then
              echo "ERROR in `basename ${0}`: could not file with \"hemi-LR\" and \"avg_bold.npy\" in \"${prf_dir}\""
              exit 1
            fi

            if [[ ! -f ${dm_file} ]]; then
              echo "ERROR in `basename ${0}`: could not file \"${dm_file}\""
              exit 1
            fi
             
            bold_flag="--in ${bold_file}"
            dm_flag="--dm ${dm_file}"

            # old params
            if [[ ! -z ${prf_params} ]]; then
              echo "Refitting \"${prf_params}\""
              
              # rename iter fit to grid; iter will be the refitted data
              if [[ ${prf_params} == *"stage-iter"* ]]; then
                file_grid=${prf_params//stage-iter/stage-grid}
                cp ${prf_params} ${file_grid} 2>/dev/null
              fi
              par_flag="--old ${prf_params}"
            fi

          fi

          if [[ ${run_locally} -eq 0 ]]; then
            if [[ ! -z ${SGE_QUEUE} ]]; then
              QUEUE=${SGE_QUEUE}
            else
              QUEUE=${SGE_QUEUE_LONG}
            fi

            job="qsub -q ${QUEUE} -pe smp ${n_jobs} -wd ${prf_dir} -N ${base}_task-${task}_model-${model} ${DIR_SCRIPTS}/bin/${script_name}"
          else
            job=${script_name}
          fi
  
          # define call to call_prf
          export DISPLAY=:0
          cmd="""${job} ${grid_flag} ${fit_hrf} ${clip_flag} \
            -s ${sub_id} \
            -n ${nr} \
            -t ${task} \
            -o ${prf_dir} \
            -i ${full_input} \
            -p ${use_pngdir} \
            -u ${use_space} \
            --${use_model} \
            --n_jobs ${n_jobs} \
            --n_pix ${n_pix} \
            ${pyb_flag} \
            ${folds_flag} \
            ${tr_flag} \
            ${kwargs_file} \
            ${save_grid} \
            ${lbl_flag} \
            ${zscore_flag} \
            ${raw_flag} \
            ${verb_flag} \
            ${OW_flag} \
            ${use_constr} \
            ${fit_flag} \
            ${cut_vols} \
            ${bounds_flag} \
            ${merge_flag} \
            ${bold_flag} \
            ${dm_flag} \
            ${redo_bold} \
            ${skip_flag} \
            ${trans_flag} \
            ${par_flag}"""

          if [[ ${run_locally} -eq 1 ]]; then
            echo ${cmd}
          fi

          cmd_file=${prf_dir}/sub-${sub_id}_ses-${nr}_task-${task}_desc-command.txt
          (
            echo "### New invocation of call_prf @`date`"
            echo "`echo ${cmd} | tr '\n' ' '`"
            echo
          ) >> ${cmd_file}

          ${cmd}
          if [[ $? -ne 0 ]]; then
            echo "ERROR in `basename ${0}`: call_prf did not execute cleanly"
            exit 1
          fi

        fi

      else
        echo "`basename ${prf_params}` file exists"
        continue
      fi
      
    done

  else
    echo "${sub_name}: Directory \"${full_input}\" not valid."
  fi

done

#-----------------------------------------------------------------------------
# Calculate time spent using 'let'
echo
echo "---------------------------------------------------------------------------------------------------"
end=`date +%s`
end_date=`date`
printf "Done at ${end_date}\n"

let deltatime=end-start
let hours=deltatime/3600
let minutes=(deltatime/60)%60
let seconds=deltatime%60
printf "Time spent: %d:%02d:%02d\n" ${hours} ${minutes} ${seconds}
echo "---------------------------------------------------------------------------------------------------"
