#!/usr/bin/env bash

#---------------------------------------------------------------------------------------------------------
# check if there's is a setup file containing the major paths and source it if it exists
call_loadsetup
source ${SETUP_FILE}

#---------------------------------------------------------------------------------------------------------
# Create help text
function Usage {
    cat <<EOF

---------------------------------------------------------------------------------------------------
spinoza_scanner2bids

convert raw data from the scanner to nifti format. Depending on which session we're analyzing, we'll
use either call_dcm2niix.py (session 1 - which is FromScannerToBIDS.py from M. Aqil) which can deal
nicely with the anatomical and functional stuff or call_dcm2niix.sh, which is more specific for the
line scanning stuff.

Input options:
  -s <subject>        subject ID (e.g., 01). Can also be comma-separated list: 01,02,05
  -n <session>        session ID (e.g., 1, 2, or none)
  <project root>      directory to output BIDSified data to
  <sourcedata>        directory containing to be converted data
  -q <queue>          submit jobs to a specific queue. Defaults to SGE_QUEUE_LONG in spinoza_setup
  -o|--ow             Overwrite existing output
  --full              Overwrite existing output + created nifti folder
  --lines             flag to tell we're dealing with a line-scanning session. By default 'regular',
                      which means standard whole-brain acquisitions.
  --inv               add individual inversion files from anatomies in 'anat' folder
  --dcm_fix           Extremely large par/rec's cannot be converted with 'dcm2niix'. Normal fMRI 
                      sessions are converted using 'call_pydcm2niix', but this flag points it to 'call
                      _dcm2niix', the same that is used for line-scanning sessions. It pipes the output 
                      from dcm2niix to a log file to monitor 'Catastrophic errors'. It then tries to 
                      convert these with 'parrec2nii', which comes with the python pacakge 'nibabel'.
  --take-avg-tr       Take the average over all TRs from the par file, rather than the first in the
                      sequence of TRs
  --ap|--pa|--lr|--rl Specifies the phase-encoding direction for the BOLD run. The phase-encoding 
                      for the FMAP will be automatically inverted. This flag can be specified to be
                      a bit more flexible than using the PE_DIR_BOLD-variable in the setup file
  --no_lpi            do not reorient files to LPI. If you want to use NORDIC or use fMRIprep's out-
                      puts on more raw data, I'd advise you to reorient to LPI and to NOT use this 
                      flag. This flag is mainly here because it can take some time with big files
                      which slows down debugging.
  --sge               submit individual subjects to cluster as call_parrec2nii can take a while..
  --phys              run only physiology conversion

Example:
  spinoza_scanner2bids /path/to/project_root /path/to/your/project/sourcedata     # regular
  spinoza_scanner2bids -n 1/path/to/project_root /path/to/your/project/sourcedata # regular|ses-1
  spinoza_scanner2bids (shows this help text)                                     # help
  spinoza_scanner2bids --lines -n 2 DIR_DATA_HOME DIR_DATA_SOURCE                 # lines|ses-2

Notes:
  Assumes the following data structure:
  PROJECT
  └── sourcedata
      └── sub-001
          └── ses-1
              ├── task
              └── DICOMs/PARRECs
              
  Converts to:
  PROJECT
  └── sub-001
      └── ses-1
          ├── anat
          ├── func
          ├── fmap
          └── phase

---------------------------------------------------------------------------------------------------------

EOF
    exit 1
}

#---------------------------------------------------------------------------------------------------------
# Deal with arguments

# Check for subject & session flags
OW=""
FULL_OW=""
SES_FLAG=""
SES_TYPE="regular"
ADD_INV=""
DCM_FIX=""
ORIENT_FLAG=""
PROT_FLAG=""
PE_FLAG=""
SGE_FLAG=0
DEBUG_MODE=0
PHYS_FLAG=""
while getopts :-:os:n:r:q: argument
do
  case ${argument} in
    -)
      case "${OPTARG}" in
        lines)
          SES_FLAG="--lines"
          SES_TYPE="lines"
          ;;
        inv)
          ADD_INV="--inv"
          ;;       
        dcm_fix)
          DCM_FIX="--dcm_fix"
          SES_TYPE="lines"
          ;;  
        take-avg-tr)
          PROT_FLAG="--take-avg-tr"
          ;;         
        ap)
          PE_FLAG="--ap"
          ;;          
        pa)
          PE_FLAG="--pa"
          ;;         
        lr)
          PE_FLAG="--lr"
          ;;         
        rl)
          PE_FLAG="--rl"
          ;;        
        no_lpi)
          ORIENT_FLAG="--no_lpi"
          ;;       
        ow)
          OW="--ow"
          ;;  
        phys)
          PHYS_FLAG="--phys"
          ;;           
        full)
          FULL_OW="--full"
          ;;  
        sge)
          SGE_FLAG=1
          if [[ ! -d ${DIR_LOGS} ]]; then
            mkdir -p ${DIR_LOGS} 2>/dev/null
          fi
          ;;   
        debug)
          DEBUG_MODE=1
          ;;           
        *)
          if [ "$OPTERR" = 1 ] && [ "${optspec:0:1}" != ":" ]; then
            echo "Unknown option --${OPTARG}, did you mean \"--lines\"?"
            exit 1
          fi
          ;;  
      esac;;    
    s)  sub=${OPTARG}
          ;;
    n)  ses=${OPTARG}
          ;;     
    o)  OW="--ow"
          ;;    
    r)  RUNS="-r ${OPTARG}"                                 
          ;;
    q)  SGE_QUEUE=${OPTARG}
          ;;           
  esac
done

if [[ $# -lt 2 ]] ; then
  Usage >&2
  exit 1
fi

PROJECT_ROOT=${@:$OPTIND:1}
SOURCEDATA=${@:$OPTIND+1:1}

if [[ -z ${sub} ]]; then
  # loop through subjects
  search="${SOURCEDATA}/${SUBJECT_PREFIX}*"
else
  # read specified subjects into array
  IFS=', ' read -r -a search <<< "${sub}"
  search=${search[@]}
  unset IFS
fi

# 'import' some bash functions
source call_bashhelper

#-----------------------------------------------------------------------------
# Start clock
#-----------------------------------------------------------------------------
echo
echo "==================================================================================================="
printf "Convert raw data to nifti using dcm2niix/parrec2nii\n"
start=`date +%s`
start_date=`date`

printf "Started at ${start_date}\n"
echo "==================================================================================================="

#-----------------------------------------------------------------------------
# Run it
for subID in ${search}; do

  # collect subject name
  if [[ ! -z ${sub} ]]; then
    sub_name=${SUBJECT_PREFIX}${subID}
  else
    sub_name=$(basename ${subID})
  fi

  if [[ ! -z ${ses} ]]; then
    nr=`echo ${ses} | sed -e 's/^[[:space:]]*//'`
    base_path=${sub_name}/ses-${nr}
    base=${sub_name}_ses-${nr}
    msg="${sub_name} ses-${ses}: already processed"
  else
    base_path=${sub_name}
    base=${sub_name}
    msg="${sub_name}: already processed"
  fi  

  input_dir=${SOURCEDATA}/${base_path}
  output_dir=${input_dir}/nifti
  bids_dir=${PROJECT_ROOT}/${base_path}

  # full overwrite
  if [[ ! -z ${FULL_OW} ]]; then
    rm -r ${output_dir} 2>/dev/null
    rm -r ${bids_dir} 2>/dev/null
  fi
  
  if [[ ${SES_TYPE} == "regular" ]]; then

    if [[ -d ${bids_dir}/anat && -d ${bids_dir}/func ]]; then
      nr_anat=`ls -l ${bids_dir}/anat | grep "total" | cut -d' ' -f2`
      nr_func=`ls -l ${bids_dir}/func | grep "total" | cut -d' ' -f2`
      if [ ${nr_anat} -ne 0 ] && [ ${nr_func} -ne 0 ]; then
        echo "${msg}; use \"master -m 02a --ow\" to overwrite"
        echo " anat = ${nr_anat} | func = ${nr_func}"
        continue
      fi
    fi

    if [[ ! -d ${input_dir} ]]; then
      echo "${sub_name}: \"${input_dir}\" does not exist"
      continue
    else

      echo
      echo "**************************************** Processing ${sub_name} ***************************************"
      
      # We're dealing with session-1, the anatomical and pRF-mapping part, so we'll use FromScannerToBIDS.py/call_dcm2niix.py
      echo "Regular scan session (whole-brain data); using call_pydcm2niix"
      call_pydcm2niix ${input_dir} True False 2019

      if [[ ${reorient} -eq 1 ]]; then
        echo "Reorienting images to LPI (conform fMRIPrep)"
        # for convenience, reorient all files to RAS+ (used by nibabel & fMRIprep)
        files=`find ${bids_dir} -type f -name "*.nii.gz"`
        for f in ${files[@]}; do
          val=`fslval ${f} qform_xorient`
          if [ ${val} != "Left-to-Right" ]; then
            call_reorient -i ${f} -c nb
          fi
        done
      fi

    fi

  elif [[ ${SES_TYPE} == "lines" ]]; then

    # check if input directory exists
    if [[ ! -d ${input_dir} ]]; then
      echo "${sub_name}: could not find input directory \"${input_dir}\""
      continue
    else
  
      if [[ ! -d ${bids_dir}/anat || ! -d ${bids_dir}/func || ! -z ${OW} || ${DEBUG_MODE} -eq 1 ]]; then

        if [[ ${DCM_FIX} -eq 1 ]]; then
          intro_txt="Regular session, but with call_parrec2nii fix for big PAR/REC files"
        else
          intro_txt="Exotic session (e.g., line-scanning); using call_dcm2niix"
        fi


        if [[ ${SGE_FLAG} -eq 1 ]]; then
          if [[ ! -z ${SGE_QUEUE} ]]; then
            QUEUE=${SGE_QUEUE}
          else
            QUEUE=${SGE_QUEUE_LONG}
          fi        
          job="qsub -q ${QUEUE} -wd ${DIR_LOGS} -pe smp 1 -N ${base}_desc-dcm2bids"
        else
          job="bash"
          echo
          echo "**************************************** Processing ${sub_name} ***************************************"
          echo ${intro_txt}
        fi

        if [[ ${DEBUG_MODE} -eq 1 ]]; then
          echo " OW          = ${OW}"
          echo " FULL_OW     = ${FULL_OW}"
          echo " SES_FLAG    = ${SES_FLAG}"
          echo " ADD_INV     = ${ADD_INV}"
          echo " DCM_FIX     = ${DCM_FIX}"
          echo " ORIENT_FLAG = ${ORIENT_FLAG}"
          echo " PROT_FLAG   = ${PROT_FLAG}"
          echo " PE_FLAG     = ${PE_FLAG}"
          echo " RUNS FLAG   = ${RUNS}"
          echo " PHYS FLAG   = ${PHYS_FLAG}"
        fi

        cmd="""${job} ${DIR_SCRIPTS}/bin/call_bids \
          ${SES_FLAG} \
          ${ADD_INV} \
          ${DCM_FIX} \
          ${ORIENT_FLAG} \
          ${PROT_FLAG} \
          ${PE_FLAG} \
          ${OW} \
          ${PHYS_FLAG} \
          -i ${input_dir} -o ${output_dir} -b ${bids_dir} -n ${base} ${RUNS}"""

        # echo command if running locally
        if [[ ${SGE_FLAG} -eq 0 ]]; then
          echo
          echo ${cmd}
        fi

        ${cmd}
          
      else
        echo "${msg}; use \"master -m 02a --ow\" (re-runs bidsification) or \"master -m 02a --full\" (also re-runs conversion) to overwrite"
      fi
    fi
  else
    echo "Invalid session-type \"${SES_TYPE}\". Must be 'regular' or 'lines'"
    continue
  fi

done

#---------------------------------------------------------------------------------------------------------
# make dataset_description file if it doesn't exist. User enters a line for the description

if [[ ! -f ${DIR_DATA_HOME}/dataset_description.json ]]; then

  cd ${DIR_DATA_HOME}
  echo "enter the name of the project and press [ENTER]: " && read DESCRIPTION

  (
  echo "{"
  echo "    \"Name\": \"${DESCRIPTION}\","
  echo "    \"BIDSVersion\": \"1.2.2\","
  echo "    \"License\": \"RECOMMENDED. What license is this dataset distributed under?. The use of license name abbreviations is suggested for specifying a license\","
  echo "    \"Authors\": ["
  echo "        \"G.J. Heij\""
  echo "    ],"
  echo "    \"Acknowledgements\": \"OPTIONAL. List of individuals who contributed to the creation/curation of the dataset\","
  echo "    \"HowToAcknowledge\": \"OPTIONAL. Instructions how researchers using this dataset should acknowledge the original authors. This field can also be used to define a publication that should be cited in publications that use the dataset\","
  echo "    \"Funding\": ["
  echo "        \"OPTIONAL. List of sources of funding (grant numbers)\""
  echo "    ],"
  echo "    \"ReferencesAndLinks\": ["
  echo "        \"OPTIONAL. List of references to publication that contain information on the dataset, or links\","
  echo "        \"https://github.com/Donders-Institute/bidscoin\""
  echo "    ],"
  echo "    \"DatasetDOI\": \"OPTIONAL. The Document Object Identifier of the dataset (not the corresponding paper)\""
  echo "}"
  ) > dataset_description.json

  cd $OLDPWD

fi

#-----------------------------------------------------------------------------
# Calculate time spent using 'let'
echo
echo "---------------------------------------------------------------------------------------------------"
end=`date +%s`
end_date=`date`
printf "Done at ${end_date}\n"

let deltatime=end-start
let hours=deltatime/3600
let minutes=(deltatime/60)%60
let seconds=deltatime%60
printf "Time spent: %d:%02d:%02d\n" ${hours} ${minutes} ${seconds}
echo "---------------------------------------------------------------------------------------------------"
echo
